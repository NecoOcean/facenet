{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于FaceNet的人脸识别系统\n",
    "\n",
    "**项目功能**：人脸注册、人脸识别、人脸验证\n",
    "\n",
    "**技术栈**：PyTorch + MTCNN + Inception ResNet v1 + Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖（首次运行取消注释）\n",
    "# !pip install torch torchvision facenet-pytorch opencv-python matplotlib scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 环境配置与库导入\n",
    "# ============================================================\n",
    "# 设置离线模式，避免从Hugging Face Hub下载模型时网络超时\n",
    "import os\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'          # 禁用HuggingFace在线下载\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'    # 禁用Transformers在线下载\n",
    "\n",
    "# ---- 基础库导入 ----\n",
    "import random, pickle                       # random: 随机数生成; pickle: 对象序列化\n",
    "import numpy as np                          # NumPy: 数值计算库\n",
    "import matplotlib.pyplot as plt             # Matplotlib: 绑图库\n",
    "from PIL import Image                       # PIL: 图像处理库\n",
    "from tqdm import tqdm                       # tqdm: 进度条显示\n",
    "from collections import defaultdict         # defaultdict: 带默认值的字典\n",
    "\n",
    "# ---- PyTorch相关库导入 ----\n",
    "import torch                                # PyTorch核心库\n",
    "import torch.nn as nn                       # 神经网络模块\n",
    "import torch.nn.functional as F             # 函数式API(激活函数、损失函数等)\n",
    "import torch.optim as optim                 # 优化器(Adam、SGD等)\n",
    "from torch.utils.data import Dataset, DataLoader  # 数据集和数据加载器\n",
    "import torchvision.transforms as T          # 图像变换(数据增强)\n",
    "\n",
    "# ---- 人脸识别专用库 ----\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1  \n",
    "# MTCNN: 多任务级联卷积网络，用于人脸检测和对齐\n",
    "# InceptionResnetV1: FaceNet的骨干网络，用于特征提取\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc  # scikit-learn: ROC曲线和AUC计算\n",
    "\n",
    "# ============================================================\n",
    "# 配置Matplotlib中文字体支持\n",
    "# ============================================================\n",
    "import matplotlib\n",
    "import platform\n",
    "\n",
    "# 根据操作系统选择合适的中文字体\n",
    "if platform.system() == 'Windows':\n",
    "    # Windows系统优先使用微软雅黑\n",
    "    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS']\n",
    "elif platform.system() == 'Darwin':  # macOS\n",
    "    # macOS系统使用苹方或黑体\n",
    "    plt.rcParams['font.sans-serif'] = ['PingFang SC', 'Heiti SC', 'Arial Unicode MS']\n",
    "else:  # Linux\n",
    "    # Linux系统使用文泉驿或Noto字体\n",
    "    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'DejaVu Sans']\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决坐标轴负号'-'显示为方块的问题\n",
    "\n",
    "# ============================================================\n",
    "# 设置随机种子，确保实验可重复性\n",
    "# ============================================================\n",
    "random.seed(42)         # Python内置随机数种子\n",
    "np.random.seed(42)      # NumPy随机数种子\n",
    "torch.manual_seed(42)   # PyTorch CPU随机数种子\n",
    "# 注: 如果使用GPU,还需设置 torch.cuda.manual_seed(42)\n",
    "\n",
    "# ============================================================\n",
    "# 选择计算设备(GPU/CPU)\n",
    "# ============================================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.is_available() 检查是否有可用的NVIDIA GPU\n",
    "# 如果有GPU则使用'cuda'，否则使用'cpu'\n",
    "\n",
    "print(f'PyTorch: {torch.__version__}, Device: {device}')\n",
    "print(f'Matplotlib字体: {plt.rcParams[\"font.sans-serif\"][:2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 项目配置类 - 集中管理所有超参数和路径\n",
    "# ============================================================\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    项目配置类\n",
    "    将所有可调参数集中管理，便于实验调优和代码维护\n",
    "    \"\"\"\n",
    "    \n",
    "    # ---- 数据配置 ----\n",
    "    DATA_ROOT = './lfw'              # LFW数据集根目录\n",
    "    IMAGE_SIZE = 160                 # 输入图像尺寸，FaceNet标准为160×160\n",
    "    MIN_IMAGES_PER_CLASS = 2         # 每个人最少需要的图片数(用于构建正样本对)\n",
    "    \n",
    "    # ---- 训练超参数 ----\n",
    "    BATCH_SIZE = 64                  # 批次大小，影响GPU显存占用和训练稳定性\n",
    "    NUM_WORKERS = 8                  # 数据加载的并行进程数，加速数据读取\n",
    "    EPOCHS = 100                     # 训练轮数\n",
    "    LEARNING_RATE = 0.0005           # 初始学习率，使用较小值避免破坏预训练权重\n",
    "    WEIGHT_DECAY = 5e-4              # L2正则化系数，防止过拟合\n",
    "    EMBEDDING_DIM = 128              # 人脸嵌入向量维度，FaceNet论文使用128\n",
    "    PRETRAINED = 'vggface2'          # 预训练权重来源：vggface2或casia-webface\n",
    "    MARGIN = 0.2                     # Triplet Loss的边界值，控制类间距离下限\n",
    "    SAVE_FREQ = 10                   # 模型保存频率，每N轮保存一次\n",
    "    THRESHOLD = 0.6                  # 人脸验证/识别的距离阈值\n",
    "    \n",
    "    # ---- 输出目录配置 ----\n",
    "    OUTPUT_ROOT = './output'                      # 输出根目录\n",
    "    CHECKPOINT_DIR = './output/checkpoints'       # 模型权重保存目录\n",
    "    CACHE_DIR = './output/cache'                  # 数据缓存目录(预处理后的人脸)\n",
    "    DATABASE_DIR = './output/database'            # 人脸数据库目录(注册的人脸特征)\n",
    "    RESULTS_DIR = './output/results'              # 结果输出目录(图表、评估结果)\n",
    "    \n",
    "    # ---- 具体文件路径 ----\n",
    "    CACHE_PATH = './output/cache/lfw_cache.pkl'           # 预处理人脸缓存文件\n",
    "    DATABASE_PATH = './output/database/face_database.pkl' # 人脸数据库文件\n",
    "    LOSS_CURVE_PATH = './output/results/loss_curve.png'   # 训练损失曲线图\n",
    "    EVAL_RESULTS_PATH = './output/results/evaluation_results.png'  # 评估结果图\n",
    "    MULTI_FACE_PATH = './output/results/multi_face_result.png'     # 多人脸识别结果图\n",
    "\n",
    "# 创建配置实例\n",
    "cfg = Config()\n",
    "\n",
    "# 创建所有必要的输出目录\n",
    "# os.makedirs(path, exist_ok=True) 会自动创建不存在的目录，已存在则跳过\n",
    "for dir_path in [cfg.CHECKPOINT_DIR, cfg.CACHE_DIR, cfg.DATABASE_DIR, cfg.RESULTS_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# 打印关键配置信息\n",
    "print('配置完成! ')\n",
    "print(f'  BATCH_SIZE: {cfg.BATCH_SIZE}')\n",
    "print(f'  EPOCHS: {cfg.EPOCHS}')\n",
    "print(f'  LEARNING_RATE: {cfg.LEARNING_RATE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 数据集定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 数据增强策略定义\n",
    "# ============================================================\n",
    "# 数据增强是提高模型泛化能力的重要技术\n",
    "# 通过对训练图像进行随机变换，让模型学习到更鲁棒的特征\n",
    "# 项目要求：至少实现3种数据增强方法\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    # 1. 水平翻转 - 概率50%将图像左右镜像\n",
    "    # 作用：人脸具有对称性，翻转后仍是有效样本，增加样本多样性\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    \n",
    "    # 2. 随机旋转 - 在±15度范围内随机旋转\n",
    "    # 作用：模拟人脸在实际场景中的轻微倾斜\n",
    "    T.RandomRotation(degrees=15),\n",
    "    \n",
    "    # 3. 颜色抖动 - 随机调整亮度、对比度、饱和度、色调\n",
    "    # 作用：模拟不同光照条件，提高模型对光照变化的鲁棒性\n",
    "    T.ColorJitter(\n",
    "        brightness=0.3,    # 亮度变化范围：[1-0.3, 1+0.3]\n",
    "        contrast=0.3,      # 对比度变化范围\n",
    "        saturation=0.2,    # 饱和度变化范围\n",
    "        hue=0.1           # 色调变化范围\n",
    "    ),\n",
    "    \n",
    "    # 4. 随机仿射变换 - 随机平移\n",
    "    # 作用：模拟人脸在图像中位置的微小变化\n",
    "    T.RandomAffine(\n",
    "        degrees=0,                      # 不额外旋转（已在上面处理）\n",
    "        translate=(0.1, 0.1)           # 水平和垂直方向各最多平移10%\n",
    "    ),\n",
    "    \n",
    "    # 5. 高斯模糊 - 随机添加模糊效果\n",
    "    # 作用：模拟拍摄时的对焦模糊，提高模型对图像质量的容忍度\n",
    "    T.GaussianBlur(\n",
    "        kernel_size=3,                 # 模糊核大小\n",
    "        sigma=(0.1, 2.0)              # 标准差范围，随机选择\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LFW数据集类 - 带内存缓存版本\n",
    "# ============================================================\n",
    "class LFWDatasetCached(Dataset):\n",
    "    \"\"\"\n",
    "    LFW (Labeled Faces in the Wild) 人脸数据集 - 内存缓存版本\n",
    "    \n",
    "    特点：\n",
    "    1. 首次运行时使用MTCNN检测并对齐所有人脸，将结果缓存到磁盘\n",
    "    2. 后续运行直接加载缓存，大幅提升数据加载速度\n",
    "    3. 支持可选的数据增强\n",
    "    \n",
    "    LFW数据集简介：\n",
    "    - 包含5749位公众人物的13233张人脸图像\n",
    "    - 是人脸验证领域的标准测试基准\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, min_images=2, augment=False, cache_path=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        \n",
    "        Args:\n",
    "            root_dir: LFW数据集根目录，结构为 root_dir/人名/图片.jpg\n",
    "            min_images: 每个人物最少需要的图片数，少于此数的人物将被过滤\n",
    "            augment: 是否启用数据增强（训练时为True，评估时为False）\n",
    "            cache_path: 缓存文件路径\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.augment = augment\n",
    "        self.cache_path = cache_path or cfg.CACHE_PATH\n",
    "        \n",
    "        # 初始化MTCNN人脸检测器\n",
    "        # image_size: 输出人脸图像尺寸\n",
    "        # margin: 人脸边界框外扩像素数，保留更多上下文\n",
    "        self.mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "        \n",
    "        # 数据存储结构\n",
    "        self.classes = []           # 类别名称列表（人名）\n",
    "        self.class_to_idx = {}      # 类别名称到索引的映射\n",
    "        self.samples = []           # 样本列表，每个元素为(face_tensor, label)\n",
    "        \n",
    "        # 尝试加载缓存，如果不存在则构建\n",
    "        if os.path.exists(self.cache_path):\n",
    "            print(f'加载缓存: {self.cache_path}')\n",
    "            self._load_cache()\n",
    "        else:\n",
    "            print('构建数据集并缓存到内存...')\n",
    "            self._build_and_cache(min_images)\n",
    "    \n",
    "    def _build_and_cache(self, min_images):\n",
    "        \"\"\"\n",
    "        构建数据集并将所有预处理后的人脸缓存到磁盘\n",
    "        \n",
    "        流程：\n",
    "        1. 遍历数据目录，筛选有足够图片的人物\n",
    "        2. 对每张图片使用MTCNN检测人脸并对齐\n",
    "        3. 将处理后的tensor保存到缓存文件\n",
    "        \"\"\"\n",
    "        idx = 0                     # 类别索引计数器\n",
    "        raw_samples = []            # 临时存储(图片路径, 标签)\n",
    "        \n",
    "        # 遍历数据目录\n",
    "        for name in sorted(os.listdir(self.root_dir)):\n",
    "            path = os.path.join(self.root_dir, name)\n",
    "            if not os.path.isdir(path): \n",
    "                continue\n",
    "            \n",
    "            # 获取该人物的所有图片\n",
    "            imgs = [f for f in os.listdir(path) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "            \n",
    "            # 过滤图片数量不足的人物\n",
    "            if len(imgs) >= min_images:\n",
    "                self.classes.append(name)\n",
    "                self.class_to_idx[name] = idx\n",
    "                for img in imgs:\n",
    "                    raw_samples.append((os.path.join(path, img), idx))\n",
    "                idx += 1\n",
    "        \n",
    "        print(f'类别: {len(self.classes)}, 图像: {len(raw_samples)}')\n",
    "        \n",
    "        # 预处理所有图像\n",
    "        print('预处理人脸图像...')\n",
    "        for path, label in tqdm(raw_samples, desc='Processing'):\n",
    "            try:\n",
    "                # 读取图像并转为RGB格式\n",
    "                img = Image.open(path).convert('RGB')\n",
    "                \n",
    "                # 使用MTCNN检测并对齐人脸\n",
    "                # 返回值为归一化后的人脸tensor，形状为[3, 160, 160]\n",
    "                face = self.mtcnn(img)\n",
    "                \n",
    "                if face is None:\n",
    "                    # 如果MTCNN检测失败，直接resize图像作为备选方案\n",
    "                    img = img.resize((cfg.IMAGE_SIZE, cfg.IMAGE_SIZE))\n",
    "                    face = T.ToTensor()(img)                    # 转为tensor [0,1]\n",
    "                    face = T.Normalize([0.5]*3, [0.5]*3)(face)  # 归一化到[-1,1]\n",
    "                \n",
    "                # 保存到samples列表，注意转移到CPU以节省GPU显存\n",
    "                self.samples.append((face.cpu(), label))\n",
    "            except Exception as e:\n",
    "                print(f'跳过 {path}: {e}')\n",
    "        \n",
    "        # 保存缓存到磁盘\n",
    "        self._save_cache()\n",
    "        print(f'缓存完成: {len(self.samples)} 张人脸')\n",
    "    \n",
    "    def _save_cache(self):\n",
    "        \"\"\"将数据集缓存保存到磁盘\"\"\"\n",
    "        cache_data = {\n",
    "            'classes': self.classes,\n",
    "            'class_to_idx': self.class_to_idx,\n",
    "            'samples': self.samples\n",
    "        }\n",
    "        with open(self.cache_path, 'wb') as f:\n",
    "            pickle.dump(cache_data, f)\n",
    "        print(f'缓存已保存: {self.cache_path}')\n",
    "    \n",
    "    def _load_cache(self):\n",
    "        \"\"\"从磁盘加载数据集缓存\"\"\"\n",
    "        with open(self.cache_path, 'rb') as f:\n",
    "            cache_data = pickle.load(f)\n",
    "        self.classes = cache_data['classes']\n",
    "        self.class_to_idx = cache_data['class_to_idx']\n",
    "        self.samples = cache_data['samples']\n",
    "        print(f'加载成功: {len(self.classes)} 类, {len(self.samples)} 张')\n",
    "    \n",
    "    def __len__(self): \n",
    "        \"\"\"返回数据集大小\"\"\"\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的样本\n",
    "        \n",
    "        Args:\n",
    "            idx: 样本索引\n",
    "        \n",
    "        Returns:\n",
    "            face: 人脸tensor，形状[3, 160, 160]\n",
    "            label: 类别标签（整数）\n",
    "        \"\"\"\n",
    "        face, label = self.samples[idx]\n",
    "        \n",
    "        # 训练时应用数据增强\n",
    "        if self.augment:\n",
    "            # 先将tensor转回PIL Image进行增强\n",
    "            face_pil = T.ToPILImage()(face * 0.5 + 0.5)  # 反归一化：[-1,1] -> [0,1]\n",
    "            face_pil = train_transforms(face_pil)         # 应用数据增强\n",
    "            face = T.ToTensor()(face_pil)                 # 转回tensor\n",
    "            face = T.Normalize([0.5]*3, [0.5]*3)(face)   # 重新归一化\n",
    "        \n",
    "        return face, label\n",
    "\n",
    "print('数据增强策略: 水平翻转、随机旋转、颜色抖动、随机平移、高斯模糊')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 三元组数据集类 - 用于Triplet Loss训练\n",
    "# ============================================================\n",
    "class TripletDataset(Dataset):\n",
    "    \"\"\"\n",
    "    三元组数据集包装器\n",
    "    \n",
    "    将普通的(图像, 标签)数据集转换为(锚点, 正样本, 负样本, 标签)格式\n",
    "    用于Triplet Loss训练\n",
    "    \n",
    "    三元组采样策略：\n",
    "    - 锚点(Anchor): 当前样本\n",
    "    - 正样本(Positive): 与锚点同一类别的另一个样本\n",
    "    - 负样本(Negative): 与锚点不同类别的随机样本\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset: 基础数据集，需实现__getitem__返回(face, label)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        # 提取所有样本的标签\n",
    "        self.labels = [s[1] for s in dataset.samples]\n",
    "        \n",
    "        # 构建标签到样本索引的映射表，便于快速查找同类样本\n",
    "        # 例：{0: [0, 5, 10], 1: [1, 2, 8], ...}\n",
    "        self.label_to_idx = defaultdict(list)\n",
    "        for i, l in enumerate(self.labels):\n",
    "            self.label_to_idx[l].append(i)\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取一个三元组样本\n",
    "        \n",
    "        Returns:\n",
    "            anchor: 锚点人脸\n",
    "            positive: 正样本人脸（同一人的另一张照片）\n",
    "            negative: 负样本人脸（不同人的照片）\n",
    "            label: 锚点的类别标签\n",
    "        \"\"\"\n",
    "        # 获取锚点样本\n",
    "        anchor, label = self.dataset[idx]\n",
    "        \n",
    "        # 选择正样本：从同一类别中随机选择另一个样本\n",
    "        pos_idx = idx\n",
    "        if len(self.label_to_idx[label]) > 1:\n",
    "            # 如果该类别有多个样本，则选择不同的样本\n",
    "            while pos_idx == idx:\n",
    "                pos_idx = random.choice(self.label_to_idx[label])\n",
    "        positive, _ = self.dataset[pos_idx]\n",
    "        \n",
    "        # 选择负样本：从不同类别中随机选择\n",
    "        neg_label = label\n",
    "        while neg_label == label:\n",
    "            neg_label = random.choice(list(self.label_to_idx.keys()))\n",
    "        neg_idx = random.choice(self.label_to_idx[neg_label])\n",
    "        negative, _ = self.dataset[neg_idx]\n",
    "        \n",
    "        return anchor, positive, negative, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 创建数据集和数据加载器\n",
    "# ============================================================\n",
    "\n",
    "print('加载数据集（内存缓存版）...')\n",
    "\n",
    "# 创建基础数据集，启用数据增强（用于训练）\n",
    "# 首次运行会处理所有图像并缓存，后续直接加载缓存\n",
    "base_ds = LFWDatasetCached(\n",
    "    cfg.DATA_ROOT,               # 数据集根目录\n",
    "    cfg.MIN_IMAGES_PER_CLASS,    # 每人最少图片数\n",
    "    augment=True                 # 启用数据增强\n",
    ")\n",
    "\n",
    "# 将基础数据集包装为三元组数据集\n",
    "triplet_ds = TripletDataset(base_ds)\n",
    "\n",
    "# 创建数据加载器\n",
    "# DataLoader负责批量加载、打乱、多进程预取数据\n",
    "train_loader = DataLoader(\n",
    "    triplet_ds,\n",
    "    batch_size=cfg.BATCH_SIZE,   # 每批样本数\n",
    "    shuffle=True,                # 打乱数据顺序（训练时必须）\n",
    "    num_workers=cfg.NUM_WORKERS  # 并行加载进程数\n",
    ")\n",
    "\n",
    "print(f'批次数: {len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FaceNet模型定义\n",
    "# ============================================================\n",
    "class FaceNet(nn.Module):\n",
    "    \"\"\"\n",
    "    FaceNet人脸识别模型\n",
    "    \n",
    "    架构：\n",
    "    1. 骨干网络(Backbone): Inception ResNet v1\n",
    "       - 输入: 160×160×3 RGB图像\n",
    "       - 输出: 512维特征向量\n",
    "       \n",
    "    2. 嵌入层(Embedding): 线性层 + BatchNorm\n",
    "       - 输入: 512维特征\n",
    "       - 输出: 128维嵌入向量（L2归一化后）\n",
    "    \n",
    "    预训练权重：\n",
    "    - VGGFace2: 330万张人脸图像训练，性能最佳\n",
    "    - CASIA-WebFace: 50万张人脸图像训练\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pretrained='vggface2', emb_dim=128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pretrained: 预训练权重类型，'vggface2'或'casia-webface'或None\n",
    "            emb_dim: 输出嵌入向量维度，默认128\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 创建骨干网络\n",
    "        # pretrained=None 表示不自动下载权重，避免网络超时\n",
    "        # classify=False 表示不添加分类头，只输出特征\n",
    "        self.backbone = InceptionResnetV1(pretrained=None, classify=False)\n",
    "        \n",
    "        # 手动加载本地预训练权重\n",
    "        if pretrained:\n",
    "            # 权重文件标准缓存路径\n",
    "            weight_path = os.path.expanduser('~/.cache/torch/hub/checkpoints/20180402-114759-vggface2.pt')\n",
    "            \n",
    "            if os.path.exists(weight_path):\n",
    "                # 加载权重到CPU，避免GPU显存不足\n",
    "                state_dict = torch.load(weight_path, map_location='cpu')\n",
    "                \n",
    "                # strict=False: 允许部分权重加载\n",
    "                # 忽略不匹配的键（如分类层logits）\n",
    "                self.backbone.load_state_dict(state_dict, strict=False)\n",
    "                print(f'✓ 已加载本地权重: {weight_path}')\n",
    "            else:\n",
    "                print(f'✗ 权重文件不存在: {weight_path}')\n",
    "                print('  请先下载权重到该路径，或设置 pretrained=None 使用随机初始化')\n",
    "        \n",
    "        # 嵌入层：将512维特征映射到目标维度\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(512, emb_dim),     # 全连接层\n",
    "            nn.BatchNorm1d(emb_dim)      # 批归一化，稳定训练\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        Args:\n",
    "            x: 输入图像，形状[B, 3, 160, 160]\n",
    "        \n",
    "        Returns:\n",
    "            嵌入向量，形状[B, 128]，已L2归一化\n",
    "        \"\"\"\n",
    "        # 骨干网络提取特征\n",
    "        feat = self.backbone(x)          # [B, 512]\n",
    "        \n",
    "        # 嵌入层降维\n",
    "        emb = self.embedding(feat)       # [B, 128]\n",
    "        \n",
    "        # L2归一化：将向量投影到单位超球面上\n",
    "        # 这使得欧氏距离等价于余弦相似度\n",
    "        return F.normalize(emb, p=2, dim=1)\n",
    "\n",
    "# 创建模型实例并移至计算设备\n",
    "model = FaceNet(cfg.PRETRAINED, cfg.EMBEDDING_DIM).to(device)\n",
    "\n",
    "# 打印模型参数量\n",
    "print(f'模型参数: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Triplet Loss 损失函数定义\n",
    "# ============================================================\n",
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    基础三元组损失函数\n",
    "    \n",
    "    核心思想：\n",
    "    让同一人的人脸特征距离（正样本距离）小于不同人的距离（负样本距离），\n",
    "    且两者之间至少保持margin的间隔。\n",
    "    \n",
    "    损失公式：\n",
    "    L = max(0, d(anchor, positive) - d(anchor, negative) + margin)\n",
    "    \n",
    "    其中：\n",
    "    - d(a, p): 锚点与正样本的欧氏距离\n",
    "    - d(a, n): 锚点与负样本的欧氏距离\n",
    "    - margin: 边界值，控制类间最小距离\n",
    "    \n",
    "    训练目标：d(a, p) + margin < d(a, n)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: 边界值，典型值0.1~0.3\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        \"\"\"\n",
    "        计算三元组损失\n",
    "        \n",
    "        Args:\n",
    "            anchor: 锚点嵌入向量 [B, D]\n",
    "            positive: 正样本嵌入向量 [B, D]\n",
    "            negative: 负样本嵌入向量 [B, D]\n",
    "        \n",
    "        Returns:\n",
    "            损失值（标量）\n",
    "        \"\"\"\n",
    "        # 计算锚点-正样本距离\n",
    "        pos_dist = F.pairwise_distance(anchor, positive)\n",
    "        \n",
    "        # 计算锚点-负样本距离\n",
    "        neg_dist = F.pairwise_distance(anchor, negative)\n",
    "        \n",
    "        # Triplet Loss = max(0, pos_dist - neg_dist + margin)\n",
    "        # F.relu 实现 max(0, x) 操作\n",
    "        return F.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 带硬负样本挖掘的Triplet Loss\n",
    "# ============================================================\n",
    "class TripletLossHardMining(nn.Module):\n",
    "    \"\"\"\n",
    "    带硬负样本挖掘的三元组损失\n",
    "    \n",
    "    问题背景：\n",
    "    随机采样的三元组中，大部分负样本距离锚点很远（简单负样本），\n",
    "    这些样本的损失为0，对训练没有贡献。\n",
    "    \n",
    "    解决方案：\n",
    "    在每个batch内，根据策略选择更有信息量的负样本。\n",
    "    \n",
    "    挖掘策略：\n",
    "    1. random: 随机选择（基线）\n",
    "    2. semi-hard: 选择满足 d(a,p) < d(a,n) < d(a,p)+margin 的负样本\n",
    "       - 这类样本能提供有效梯度，同时训练稳定\n",
    "    3. hard: 选择距离最近的负样本\n",
    "       - 梯度最大，但可能导致训练不稳定\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin=0.2, mining='semi-hard'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: 边界值\n",
    "            mining: 挖掘策略，'random'/'semi-hard'/'hard'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.mining = mining\n",
    "    \n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        在batch内进行硬负样本挖掘并计算损失\n",
    "        \n",
    "        Args:\n",
    "            embeddings: batch内所有样本的嵌入向量 [B, D]\n",
    "            labels: 对应的标签 [B]\n",
    "        \n",
    "        Returns:\n",
    "            损失值\n",
    "        \"\"\"\n",
    "        # 计算batch内所有样本对的距离矩阵\n",
    "        # dist_mat[i,j] = ||embeddings[i] - embeddings[j]||\n",
    "        dist_mat = torch.cdist(embeddings, embeddings, p=2)\n",
    "        batch_size = embeddings.size(0)\n",
    "        \n",
    "        # 构建同类/异类掩码\n",
    "        labels = labels.view(-1, 1)\n",
    "        same_id = (labels == labels.T).float()   # 同一人为1，不同人为0\n",
    "        diff_id = 1 - same_id                     # 不同人为1\n",
    "        \n",
    "        # 正样本掩码：同类且不是自身\n",
    "        mask_pos = same_id.clone()\n",
    "        mask_pos.fill_diagonal_(0)\n",
    "        \n",
    "        if self.mining == 'hard':\n",
    "            # 硬挖掘：选择同类中最远的正样本，异类中最近的负样本\n",
    "            pos_dist = (dist_mat * mask_pos).max(dim=1)[0]\n",
    "            neg_dist_mat = dist_mat + 1e6 * same_id  # 同类设为极大值\n",
    "            neg_dist = neg_dist_mat.min(dim=1)[0]\n",
    "            \n",
    "        elif self.mining == 'semi-hard':\n",
    "            # 半硬挖掘：正样本取平均，负样本取最近\n",
    "            pos_dist = (dist_mat * mask_pos).sum(dim=1) / (mask_pos.sum(dim=1) + 1e-8)\n",
    "            neg_dist_mat = dist_mat + 1e6 * same_id\n",
    "            neg_dist = neg_dist_mat.min(dim=1)[0]\n",
    "            \n",
    "        else:  # random\n",
    "            # 随机策略：取平均距离\n",
    "            pos_dist = (dist_mat * mask_pos).sum(dim=1) / (mask_pos.sum(dim=1) + 1e-8)\n",
    "            neg_dist = (dist_mat * diff_id).sum(dim=1) / (diff_id.sum(dim=1) + 1e-8)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = F.relu(pos_dist - neg_dist + self.margin)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 创建损失函数和优化器\n",
    "# ============================================================\n",
    "\n",
    "# 使用基础三元组损失（配合TripletDataset使用）\n",
    "criterion = TripletLoss(cfg.MARGIN)\n",
    "\n",
    "# 也可以使用硬挖掘版本（需要修改训练循环，传入embeddings和labels）\n",
    "# criterion_hard = TripletLossHardMining(cfg.MARGIN, mining='semi-hard')\n",
    "\n",
    "# Adam优化器\n",
    "# - 自适应学习率，对每个参数使用不同的学习率\n",
    "# - weight_decay: L2正则化，防止过拟合\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=cfg.LEARNING_RATE, \n",
    "    weight_decay=cfg.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# 余弦退火学习率调度器\n",
    "# 学习率从初始值平滑衰减到eta_min，遵循余弦曲线\n",
    "# 有助于模型收敛到更好的局部最优解\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=cfg.EPOCHS,      # 一个周期的步数\n",
    "    eta_min=1e-6           # 最小学习率\n",
    ")\n",
    "\n",
    "print(f'损失函数: TripletLoss (margin={cfg.MARGIN})')\n",
    "print(f'优化器: Adam (lr={cfg.LEARNING_RATE})')\n",
    "print(f'学习率调度: CosineAnnealing (T_max={cfg.EPOCHS})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 训练函数定义\n",
    "# ============================================================\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    执行一个epoch的训练\n",
    "    \n",
    "    训练流程：\n",
    "    1. 遍历所有batch\n",
    "    2. 前向传播：计算三元组的嵌入向量\n",
    "    3. 计算损失：使用Triplet Loss\n",
    "    4. 反向传播：计算梯度\n",
    "    5. 参数更新：优化器更新权重\n",
    "    \n",
    "    Args:\n",
    "        model: FaceNet模型\n",
    "        loader: 数据加载器（返回anchor, positive, negative, label）\n",
    "        criterion: 损失函数（TripletLoss）\n",
    "        optimizer: 优化器（Adam）\n",
    "    \n",
    "    Returns:\n",
    "        平均损失值\n",
    "    \"\"\"\n",
    "    model.train()  # 设置为训练模式，启用Dropout和BatchNorm的训练行为\n",
    "    total_loss, n = 0, 0\n",
    "    \n",
    "    # 遍历所有batch\n",
    "    for a, p, neg, _ in tqdm(loader, desc='Training'):\n",
    "        # 将数据移至计算设备（GPU/CPU）\n",
    "        a = a.to(device)      # anchor: [B, 3, 160, 160]\n",
    "        p = p.to(device)      # positive: [B, 3, 160, 160]\n",
    "        neg = neg.to(device)  # negative: [B, 3, 160, 160]\n",
    "        \n",
    "        # 梯度清零\n",
    "        # PyTorch默认会累积梯度，每个batch开始前需要清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播：计算三个样本的嵌入向量，然后计算损失\n",
    "        anchor_emb = model(a)        # [B, 128]\n",
    "        positive_emb = model(p)      # [B, 128]\n",
    "        negative_emb = model(neg)    # [B, 128]\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        \n",
    "        # 反向传播：计算损失对每个参数的梯度\n",
    "        loss.backward()\n",
    "        \n",
    "        # 参数更新：根据梯度更新模型权重\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 累积损失\n",
    "        total_loss += loss.item()\n",
    "        n += 1\n",
    "    \n",
    "    # 返回平均损失\n",
    "    return total_loss / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 训练主循环\n",
    "# ============================================================\n",
    "\n",
    "# 训练历史记录\n",
    "history = {'loss': []}\n",
    "\n",
    "# 记录最佳损失，用于保存最优模型\n",
    "best_loss = float('inf')\n",
    "\n",
    "print('='*50)\n",
    "print('开始训练')\n",
    "print('='*50)\n",
    "\n",
    "# 主训练循环\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    # 打印当前epoch信息和学习率\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    print(f'\\nEpoch {epoch+1}/{cfg.EPOCHS}, LR: {current_lr:.6f}')\n",
    "    \n",
    "    # 执行一个epoch的训练\n",
    "    loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    \n",
    "    # 记录损失历史\n",
    "    history['loss'].append(loss)\n",
    "    print(f'Loss: {loss:.4f}')\n",
    "    \n",
    "    # 更新学习率（余弦退火）\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 定期保存模型检查点\n",
    "    if (epoch+1) % cfg.SAVE_FREQ == 0:\n",
    "        checkpoint_path = f'{cfg.CHECKPOINT_DIR}/facenet_ep{epoch+1}.pth'\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        # 注：这里只保存了模型权重(state_dict)\n",
    "        # 完整检查点应包含optimizer和scheduler状态，以便恢复训练\n",
    "    \n",
    "    # 保存最优模型（损失最低）\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), f'{cfg.CHECKPOINT_DIR}/facenet_best.pth')\n",
    "        print('  -> 最优模型已保存')\n",
    "\n",
    "print('\\n训练完成!')\n",
    "print(f'模型保存位置: {cfg.CHECKPOINT_DIR}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 图像显示工具函数\n",
    "# ============================================================\n",
    "from IPython.display import HTML, display\n",
    "import base64\n",
    "\n",
    "def display_image(path, width=None):\n",
    "    \"\"\"\n",
    "    以Base64嵌入方式显示图片\n",
    "    \n",
    "    解决Jupyter远程环境下图片无法显示的问题：\n",
    "    - 远程服务器上plt.show()无法直接显示图片\n",
    "    - 文件路径方式在某些环境下也有问题\n",
    "    - Base64嵌入方式将图片编码到HTML中，兼容性最好\n",
    "    \n",
    "    Args:\n",
    "        path: 图片文件路径\n",
    "        width: 可选的显示宽度（像素）\n",
    "    \"\"\"\n",
    "    # 读取图片文件并转为Base64编码\n",
    "    with open(path, 'rb') as f:\n",
    "        img_data = base64.b64encode(f.read()).decode()\n",
    "    \n",
    "    # 根据文件扩展名确定MIME类型\n",
    "    ext = path.split('.')[-1].lower()\n",
    "    mime = {\n",
    "        'png': 'image/png', \n",
    "        'jpg': 'image/jpeg', \n",
    "        'jpeg': 'image/jpeg'\n",
    "    }.get(ext, 'image/png')\n",
    "    \n",
    "    # 构造HTML img标签\n",
    "    style = f'width:{width}px' if width else 'max-width:100%'\n",
    "    html = f'<img src=\"data:{mime};base64,{img_data}\" style=\"{style}\"/>'\n",
    "    \n",
    "    # 在Notebook中显示\n",
    "    display(HTML(html))\n",
    "\n",
    "# ============================================================\n",
    "# 绘制并保存训练损失曲线\n",
    "# ============================================================\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.plot(history['loss'], 'b-', lw=2)\n",
    "\n",
    "# 设置图表标签\n",
    "plt.xlabel('Epoch')       # X轴：训练轮次\n",
    "plt.ylabel('Loss')        # Y轴：损失值\n",
    "plt.title('Training Loss')  # 标题\n",
    "plt.grid(True)            # 显示网格\n",
    "\n",
    "# 保存图表到文件\n",
    "plt.savefig(cfg.LOSS_CURVE_PATH, dpi=150)\n",
    "plt.close()  # 关闭图形，释放内存\n",
    "\n",
    "# 显示保存的图片\n",
    "print(f'训练曲线已保存: {cfg.LOSS_CURVE_PATH}')\n",
    "display_image(cfg.LOSS_CURVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 人脸注册"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 人脸数据库类 - 用于人脸注册功能\n",
    "# ============================================================\n",
    "class FaceDatabase:\n",
    "    \"\"\"\n",
    "    人脸数据库管理类\n",
    "    \n",
    "    功能：\n",
    "    1. 注册人脸：将人脸图像转换为嵌入向量并存储\n",
    "    2. 持久化：支持将数据库保存到文件和从文件加载\n",
    "    \n",
    "    数据结构：\n",
    "    db = {\n",
    "        '张三': numpy array [N, 128],  # N张照片的嵌入向量\n",
    "        '李四': numpy array [M, 128],\n",
    "        ...\n",
    "    }\n",
    "    \n",
    "    使用流程：\n",
    "    1. 创建数据库：face_db = FaceDatabase(model)\n",
    "    2. 注册人脸：face_db.register('姓名', ['图片1.jpg', '图片2.jpg'])\n",
    "    3. 保存数据库：face_db.save('database.pkl')\n",
    "    4. 加载数据库：face_db.load('database.pkl')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: FaceNet模型，用于提取人脸特征\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        \n",
    "        # 初始化MTCNN人脸检测器\n",
    "        self.mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "        \n",
    "        # 人脸数据库字典：{姓名: 嵌入向量数组}\n",
    "        self.db = {}\n",
    "    \n",
    "    def register(self, name, paths):\n",
    "        \"\"\"\n",
    "        注册人脸到数据库\n",
    "        \n",
    "        Args:\n",
    "            name: 人员姓名/ID\n",
    "            paths: 该人员的人脸图片路径列表\n",
    "        \n",
    "        Returns:\n",
    "            True: 注册成功\n",
    "            False: 注册失败（无有效人脸）\n",
    "        \"\"\"\n",
    "        self.model.eval()  # 设置为评估模式\n",
    "        embs = []\n",
    "        \n",
    "        for p in paths:\n",
    "            # 读取图像\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            \n",
    "            # 检测并对齐人脸\n",
    "            face = self.mtcnn(img)\n",
    "            \n",
    "            if face is not None:\n",
    "                # 提取嵌入向量\n",
    "                with torch.no_grad():  # 禁用梯度计算，节省内存\n",
    "                    emb = self.model(face.unsqueeze(0).to(device))\n",
    "                embs.append(emb.cpu().numpy())\n",
    "        \n",
    "        if embs:\n",
    "            # 将多张照片的嵌入向量堆叠为数组\n",
    "            self.db[name] = np.vstack(embs)\n",
    "            print(f'注册成功: {name} ({len(embs)}张)')\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def register_folder(self, folder):\n",
    "        \"\"\"\n",
    "        从文件夹批量注册人脸\n",
    "        \n",
    "        Args:\n",
    "            folder: 包含人脸图片的文件夹路径\n",
    "                   文件夹名将作为人员姓名\n",
    "        \n",
    "        Returns:\n",
    "            注册是否成功\n",
    "        \"\"\"\n",
    "        # 使用文件夹名作为人员姓名\n",
    "        name = os.path.basename(folder)\n",
    "        \n",
    "        # 获取文件夹中的所有图片\n",
    "        paths = [\n",
    "            os.path.join(folder, f) \n",
    "            for f in os.listdir(folder) \n",
    "            if f.endswith(('.jpg', '.png'))\n",
    "        ]\n",
    "        \n",
    "        return self.register(name, paths)\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        保存数据库到文件\n",
    "        \n",
    "        Args:\n",
    "            path: 保存路径（.pkl文件）\n",
    "        \"\"\"\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.db, f)\n",
    "        print(f'数据库保存: {path}')\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        从文件加载数据库\n",
    "        \n",
    "        Args:\n",
    "            path: 数据库文件路径\n",
    "        \"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            self.db = pickle.load(f)\n",
    "        print(f'数据库加载: {len(self.db)}人')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 人脸注册示例\n",
    "# ============================================================\n",
    "\n",
    "# 创建人脸数据库实例\n",
    "face_db = FaceDatabase(model)\n",
    "\n",
    "# 从LFW数据集中选择前5个人物进行注册\n",
    "# 获取所有人物目录\n",
    "sample_persons = [\n",
    "    d for d in os.listdir(cfg.DATA_ROOT) \n",
    "    if os.path.isdir(os.path.join(cfg.DATA_ROOT, d))\n",
    "][:5]  # 取前5个\n",
    "\n",
    "# 逐个注册\n",
    "for person in sample_persons:\n",
    "    person_folder = os.path.join(cfg.DATA_ROOT, person)\n",
    "    face_db.register_folder(person_folder)\n",
    "\n",
    "# 保存数据库到文件\n",
    "face_db.save(cfg.DATABASE_PATH)\n",
    "print(f'人脸数据库已保存: {cfg.DATABASE_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 人脸识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 人脸识别类 - 1:N搜索\n",
    "# ============================================================\n",
    "class FaceRecognizer:\n",
    "    \"\"\"\n",
    "    人脸识别器（1:N搜索）\n",
    "    \n",
    "    功能：\n",
    "    给定一张人脸图片，在数据库中搜索最相似的人物\n",
    "    \n",
    "    识别流程：\n",
    "    1. 检测并对齐输入图像中的人脸\n",
    "    2. 提取人脸的嵌入向量\n",
    "    3. 计算与数据库中所有人脸的距离\n",
    "    4. 返回距离最近的人物（如果距离小于阈值）\n",
    "    \n",
    "    应用场景：\n",
    "    - 门禁系统：识别来访人员身份\n",
    "    - 考勤系统：自动打卡\n",
    "    - 照片管理：按人物分类照片\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, database, threshold=0.6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: FaceNet模型\n",
    "            database: FaceDatabase实例\n",
    "            threshold: 识别阈值，距离小于此值才认为是已知人物\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.db = database\n",
    "        self.threshold = threshold\n",
    "        self.mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "    \n",
    "    def recognize(self, image_path):\n",
    "        \"\"\"\n",
    "        识别图像中的人脸\n",
    "        \n",
    "        Args:\n",
    "            image_path: 待识别图片路径\n",
    "        \n",
    "        Returns:\n",
    "            name: 识别到的人物姓名（或'Unknown'/'No face'）\n",
    "            confidence: 置信度（0~1，越高越确信）\n",
    "            distance: 与最近人物的距离\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # 读取图像\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # 检测人脸\n",
    "        face = self.mtcnn(img)\n",
    "        if face is None:\n",
    "            return 'No face', 0, float('inf')\n",
    "        \n",
    "        # 提取嵌入向量\n",
    "        with torch.no_grad():\n",
    "            emb = self.model(face.unsqueeze(0).to(device)).cpu().numpy()\n",
    "        \n",
    "        # 在数据库中搜索最相似的人物\n",
    "        min_dist = float('inf')\n",
    "        best = 'Unknown'\n",
    "        \n",
    "        for name, db_embs in self.db.db.items():\n",
    "            # 计算与该人物所有注册照片的距离，取最小值\n",
    "            # 这样即使某张注册照片质量不好，也不会影响识别\n",
    "            d = np.linalg.norm(db_embs - emb, axis=1).min()\n",
    "            if d < min_dist:\n",
    "                min_dist, best = d, name\n",
    "        \n",
    "        # 计算置信度：距离越小，置信度越高\n",
    "        # 使用线性映射：conf = 1 - dist/2，确保结果在[0,1]范围内\n",
    "        conf = max(0, 1 - min_dist/2)\n",
    "        \n",
    "        # 距离小于阈值才返回识别结果，否则返回Unknown\n",
    "        if min_dist < self.threshold:\n",
    "            return best, conf, min_dist\n",
    "        else:\n",
    "            return 'Unknown', conf, min_dist\n",
    "    \n",
    "    def recognize_show(self, path, save_path=None):\n",
    "        \"\"\"\n",
    "        识别并可视化结果\n",
    "        \n",
    "        Args:\n",
    "            path: 待识别图片路径\n",
    "            save_path: 结果图片保存路径\n",
    "        \n",
    "        Returns:\n",
    "            name: 识别结果\n",
    "            conf: 置信度\n",
    "        \"\"\"\n",
    "        # 执行识别\n",
    "        name, conf, dist = self.recognize(path)\n",
    "        save_path = save_path or f'{cfg.RESULTS_DIR}/recognize_result.png'\n",
    "        \n",
    "        # 绘制结果图\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(Image.open(path))\n",
    "        plt.title(f'{name} (置信度:{conf:.1%}, 距离:{dist:.3f})')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 保存并显示\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        display_image(save_path)\n",
    "        \n",
    "        return name, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 人脸识别功能测试\n",
    "# ============================================================\n",
    "\n",
    "# 创建识别器实例\n",
    "recognizer = FaceRecognizer(model, face_db, cfg.THRESHOLD)\n",
    "\n",
    "# 选择测试图片：使用已注册人员的一张照片\n",
    "test_person = sample_persons[0]  # 取第一个已注册的人\n",
    "test_folder = os.path.join(cfg.DATA_ROOT, test_person)\n",
    "test_img = os.path.join(test_folder, os.listdir(test_folder)[0])\n",
    "\n",
    "# 执行识别并显示结果\n",
    "print(f'测试图像: {test_img}')\n",
    "recognizer.recognize_show(test_img, save_path=f'{cfg.RESULTS_DIR}/recognize_demo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 人脸验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 人脸验证类 - 1:1比对\n",
    "# ============================================================\n",
    "class FaceVerifier:\n",
    "    \"\"\"\n",
    "    人脸验证器（1:1比对）\n",
    "    \n",
    "    功能：\n",
    "    判断两张照片是否为同一人\n",
    "    \n",
    "    验证流程：\n",
    "    1. 分别检测并对齐两张图片中的人脸\n",
    "    2. 提取两张人脸的嵌入向量\n",
    "    3. 计算两个向量之间的欧氏距离\n",
    "    4. 距离小于阈值则判定为同一人\n",
    "    \n",
    "    与识别的区别：\n",
    "    - 验证（1:1）：已知声称的身份，判断是否属实\n",
    "    - 识别（1:N）：不知道身份，在数据库中搜索\n",
    "    \n",
    "    应用场景：\n",
    "    - 身份认证：解锁手机、登录账户\n",
    "    - 证件核验：人证比对\n",
    "    - 双胞胎区分\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, threshold=0.6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: FaceNet模型\n",
    "            threshold: 验证阈值，距离小于此值判定为同一人\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        self.mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "    \n",
    "    def verify(self, path1, path2):\n",
    "        \"\"\"\n",
    "        验证两张照片是否为同一人\n",
    "        \n",
    "        Args:\n",
    "            path1: 第一张图片路径\n",
    "            path2: 第二张图片路径\n",
    "        \n",
    "        Returns:\n",
    "            is_same: 是否为同一人（True/False/None）\n",
    "            distance: 两个嵌入向量之间的距离\n",
    "            confidence: 置信度\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        faces = []\n",
    "        \n",
    "        # 检测两张图片中的人脸\n",
    "        for p in [path1, path2]:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            f = self.mtcnn(img)\n",
    "            if f is None:\n",
    "                return None, None, 'Face not detected'\n",
    "            faces.append(f)\n",
    "        \n",
    "        # 提取嵌入向量\n",
    "        with torch.no_grad():\n",
    "            e1 = self.model(faces[0].unsqueeze(0).to(device))\n",
    "            e2 = self.model(faces[1].unsqueeze(0).to(device))\n",
    "        \n",
    "        # 计算欧氏距离\n",
    "        dist = F.pairwise_distance(e1, e2).item()\n",
    "        \n",
    "        # 判定结果\n",
    "        is_same = dist < self.threshold\n",
    "        \n",
    "        # 计算置信度\n",
    "        conf = max(0, 1 - dist/2)\n",
    "        \n",
    "        return is_same, dist, conf\n",
    "    \n",
    "    def verify_show(self, p1, p2, save_path=None):\n",
    "        \"\"\"\n",
    "        验证并可视化结果\n",
    "        \n",
    "        Args:\n",
    "            p1: 第一张图片路径\n",
    "            p2: 第二张图片路径\n",
    "            save_path: 结果保存路径\n",
    "        \n",
    "        Returns:\n",
    "            验证结果（True/False/None）\n",
    "        \"\"\"\n",
    "        # 执行验证\n",
    "        result, dist, conf = self.verify(p1, p2)\n",
    "        save_path = save_path or f'{cfg.RESULTS_DIR}/verify_result.png'\n",
    "        \n",
    "        # 绘制对比图\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        \n",
    "        # 显示两张图片\n",
    "        ax[0].imshow(Image.open(p1))\n",
    "        ax[0].set_title('Image 1')\n",
    "        ax[0].axis('off')\n",
    "        \n",
    "        ax[1].imshow(Image.open(p2))\n",
    "        ax[1].set_title('Image 2')\n",
    "        ax[1].axis('off')\n",
    "        \n",
    "        # 在图片上方显示验证结果\n",
    "        status = '同一人 ✓' if result else '不同人 ✗'\n",
    "        plt.suptitle(f'{status} | 距离:{dist:.3f} | 置信度:{conf:.1%}')\n",
    "        \n",
    "        # 保存并显示\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        display_image(save_path)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 人脸验证功能测试\n",
    "# ============================================================\n",
    "\n",
    "# 创建验证器实例\n",
    "verifier = FaceVerifier(model, cfg.THRESHOLD)\n",
    "\n",
    "# 寻找有至少2张图片的人物进行验证测试\n",
    "# （验证需要同一人的两张不同照片）\n",
    "test_person = None\n",
    "test_folder = None\n",
    "\n",
    "# 首先在已注册的人物中查找\n",
    "for person in sample_persons:\n",
    "    folder = os.path.join(cfg.DATA_ROOT, person)\n",
    "    imgs = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if len(imgs) >= 2:\n",
    "        test_person = person\n",
    "        test_folder = folder\n",
    "        break\n",
    "\n",
    "# 执行验证测试\n",
    "if test_folder and test_person:\n",
    "    # 获取该人物的前两张照片\n",
    "    imgs = os.listdir(test_folder)[:2]\n",
    "    p1 = os.path.join(test_folder, imgs[0])\n",
    "    p2 = os.path.join(test_folder, imgs[1])\n",
    "    \n",
    "    print(f'验证测试人物: {test_person}')\n",
    "    print(f'图片1: {imgs[0]}')\n",
    "    print(f'图片2: {imgs[1]}')\n",
    "    \n",
    "    # 执行验证并显示结果\n",
    "    verifier.verify_show(p1, p2, save_path=f'{cfg.RESULTS_DIR}/verify_demo.png')\n",
    "else:\n",
    "    # 如果已注册人物都只有1张图片，从整个数据集中查找\n",
    "    for person in os.listdir(cfg.DATA_ROOT):\n",
    "        folder = os.path.join(cfg.DATA_ROOT, person)\n",
    "        if os.path.isdir(folder):\n",
    "            imgs = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if len(imgs) >= 2:\n",
    "                p1 = os.path.join(folder, imgs[0])\n",
    "                p2 = os.path.join(folder, imgs[1])\n",
    "                print(f'验证测试人物: {person}')\n",
    "                verifier.verify_show(p1, p2, save_path=f'{cfg.RESULTS_DIR}/verify_demo.png')\n",
    "                break\n",
    "    else:\n",
    "        print('数据集中没有找到有2张以上图片的人物')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. 模型评估\n",
    "\n",
    "使用VGGFace2预训练模型评估LFW准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 模型评估模块\n",
    "# ============================================================\n",
    "import time\n",
    "\n",
    "# 创建评估数据集（不启用数据增强）\n",
    "# 评估时应使用原始图像，避免增强带来的随机性\n",
    "print('创建无增强评估数据集...')\n",
    "eval_ds = LFWDatasetCached(cfg.DATA_ROOT, cfg.MIN_IMAGES_PER_CLASS, augment=False)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('模型评估：VGGFace2预训练模型')\n",
    "print('='*60)\n",
    "\n",
    "# ============================================================\n",
    "# 加载VGGFace2预训练模型（原始512维嵌入）\n",
    "# ============================================================\n",
    "weight_path = os.path.expanduser('~/.cache/torch/hub/checkpoints/20180402-114759-vggface2.pt')\n",
    "\n",
    "if os.path.exists(weight_path):\n",
    "    # 创建原始InceptionResnetV1模型（不经过额外的嵌入层）\n",
    "    pretrained_model = InceptionResnetV1(pretrained=None, classify=False).to(device)\n",
    "    \n",
    "    # 加载预训练权重\n",
    "    state_dict = torch.load(weight_path, map_location=device)\n",
    "    pretrained_model.load_state_dict(state_dict, strict=False)\n",
    "    pretrained_model.eval()\n",
    "    \n",
    "    print(f'✓ 已加载VGGFace2预训练权重')\n",
    "    print(f'  输出维度: 512维嵌入向量')\n",
    "else:\n",
    "    print(f'✗ 权重文件不存在: {weight_path}')\n",
    "    pretrained_model = None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LFW评估函数\n",
    "# ============================================================\n",
    "def evaluate_model_lfw(model, dataset, n_pairs=2000, save_path=None):\n",
    "    \"\"\"\n",
    "    在LFW数据集上评估模型性能\n",
    "    \n",
    "    评估方法：\n",
    "    1. 随机生成n_pairs对正样本对（同一人的两张照片）\n",
    "    2. 随机生成n_pairs对负样本对（不同人的照片）\n",
    "    3. 计算所有样本对的距离\n",
    "    4. 搜索最优阈值（使准确率最高的阈值）\n",
    "    5. 计算ROC曲线和AUC\n",
    "    \n",
    "    Args:\n",
    "        model: 要评估的模型\n",
    "        dataset: 评估数据集\n",
    "        n_pairs: 生成的样本对数量\n",
    "        save_path: 结果图保存路径\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: 最优阈值下的准确率\n",
    "        threshold: 最优阈值\n",
    "        auc: AUC分数\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print('错误：模型未加载')\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    save_path = save_path or cfg.EVAL_RESULTS_PATH\n",
    "    \n",
    "    labels, dists = [], []  # 标签和距离列表\n",
    "    samples = dataset.samples\n",
    "    \n",
    "    # 构建标签到索引的映射\n",
    "    label_to_idx = defaultdict(list)\n",
    "    for i, sample in enumerate(samples):\n",
    "        label_to_idx[sample[1]].append(i)\n",
    "    \n",
    "    print('生成评估对...')\n",
    "    \n",
    "    for _ in tqdm(range(n_pairs), desc='Evaluating'):\n",
    "        # 筛选有至少2张图片的类别（用于构建正样本对）\n",
    "        valid_labels = [l for l in label_to_idx.keys() if len(label_to_idx[l]) >= 2]\n",
    "        if not valid_labels:\n",
    "            continue\n",
    "        \n",
    "        # 随机选择一个类别\n",
    "        label = random.choice(valid_labels)\n",
    "        \n",
    "        # 从该类别中随机选择2个样本作为正样本对\n",
    "        i1, i2 = random.sample(label_to_idx[label], 2)\n",
    "        \n",
    "        try:\n",
    "            # 获取两张人脸的tensor\n",
    "            f1 = samples[i1][0].unsqueeze(0).to(device)\n",
    "            f2 = samples[i2][0].unsqueeze(0).to(device)\n",
    "            \n",
    "            # 提取嵌入向量并计算距离\n",
    "            with torch.no_grad():\n",
    "                e1, e2 = model(f1), model(f2)\n",
    "            dists.append(F.pairwise_distance(e1, e2).item())\n",
    "            labels.append(1)  # 正样本标签为1\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # 生成负样本对（不同人）\n",
    "        l2 = label\n",
    "        while l2 == label:\n",
    "            l2 = random.choice(list(label_to_idx.keys()))\n",
    "        i3 = random.choice(label_to_idx[l2])\n",
    "        \n",
    "        try:\n",
    "            f3 = samples[i3][0].unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                e3 = model(f3)\n",
    "            dists.append(F.pairwise_distance(e1, e3).item())\n",
    "            labels.append(0)  # 负样本标签为0\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # 转换为numpy数组\n",
    "    dists, labels = np.array(dists), np.array(labels)\n",
    "    print(f'收集到 {len(dists)} 个评估对 (正样本:{sum(labels)}, 负样本:{len(labels)-sum(labels)})')\n",
    "    \n",
    "    # ============================================================\n",
    "    # 搜索最优阈值\n",
    "    # ============================================================\n",
    "    best_acc, best_th = 0, 0\n",
    "    for th in np.arange(0.1, 2.0, 0.01):\n",
    "        # 预测：距离小于阈值则预测为同一人(1)\n",
    "        preds = (dists < th).astype(int)\n",
    "        acc = (preds == labels).mean()\n",
    "        if acc > best_acc:\n",
    "            best_acc, best_th = acc, th\n",
    "    \n",
    "    # ============================================================\n",
    "    # 计算ROC曲线\n",
    "    # ============================================================\n",
    "    # 注意：这里使用-dists是因为距离越小越可能是同一人\n",
    "    # sklearn的roc_curve期望分数越高越可能是正类\n",
    "    fpr, tpr, _ = roc_curve(labels, -dists)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # ============================================================\n",
    "    # 可视化结果\n",
    "    # ============================================================\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 左图：ROC曲线\n",
    "    axes[0].plot(fpr, tpr, 'b-', lw=2, label=f'ROC (AUC={roc_auc:.3f})')\n",
    "    axes[0].plot([0, 1], [0, 1], 'r--', lw=1)  # 对角线（随机猜测基准）\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_title('ROC Curve')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 右图：距离分布直方图\n",
    "    pos_dists, neg_dists = dists[labels == 1], dists[labels == 0]\n",
    "    axes[1].hist(pos_dists, bins=30, alpha=0.6, label='Same Person', color='green')\n",
    "    axes[1].hist(neg_dists, bins=30, alpha=0.6, label='Different Person', color='red')\n",
    "    axes[1].axvline(x=best_th, color='blue', linestyle='--', label=f'Threshold={best_th:.2f}')\n",
    "    axes[1].set_xlabel('Distance')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('Distance Distribution')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    display_image(save_path)\n",
    "    \n",
    "    return best_acc, best_th, roc_auc\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 效率测试函数\n",
    "# ============================================================\n",
    "def measure_efficiency(model, dataset, n_tests=50):\n",
    "    \"\"\"\n",
    "    测量特征提取和数据库搜索的时间效率\n",
    "    \n",
    "    Args:\n",
    "        model: 模型\n",
    "        dataset: 数据集\n",
    "        n_tests: 测试次数\n",
    "    \n",
    "    Returns:\n",
    "        extract_time: 单张图片特征提取时间（毫秒）\n",
    "        search_time: 数据库搜索时间（毫秒）\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    samples = dataset.samples\n",
    "    \n",
    "    # 测量特征提取时间\n",
    "    extract_times = []\n",
    "    for i in range(min(20, len(samples))):\n",
    "        face = samples[i][0].unsqueeze(0).to(device)\n",
    "        \n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = model(face)\n",
    "        \n",
    "        # GPU需要同步才能准确计时\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        extract_times.append(time.time() - start)\n",
    "    \n",
    "    # 模拟数据库搜索：在100人的数据库中查找最近邻\n",
    "    db_size = 100\n",
    "    db_embs = torch.randn(db_size, 512).to(device)\n",
    "    query_emb = torch.randn(1, 512).to(device)\n",
    "    \n",
    "    search_times = []\n",
    "    for _ in range(20):\n",
    "        start = time.time()\n",
    "        dists = torch.cdist(query_emb, db_embs)\n",
    "        _ = dists.argmin().item()\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        search_times.append(time.time() - start)\n",
    "    \n",
    "    # 转换为毫秒\n",
    "    extract_time = np.mean(extract_times) * 1000\n",
    "    search_time = np.mean(search_times) * 1000\n",
    "    \n",
    "    return extract_time, search_time\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 执行评估\n",
    "# ============================================================\n",
    "if pretrained_model is not None:\n",
    "    print('\\n运行模型评估...')\n",
    "    acc, threshold, auc_score = evaluate_model_lfw(\n",
    "        pretrained_model, eval_ds, n_pairs=2000, \n",
    "        save_path=cfg.EVAL_RESULTS_PATH\n",
    "    )\n",
    "    \n",
    "    print('\\n运行效率测试...')\n",
    "    extract_time, search_time = measure_efficiency(pretrained_model, eval_ds)\n",
    "    \n",
    "    # 打印评估结果摘要\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'{\"模型评估结果\":^56}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    print(f'LFW准确率: {acc:.2%} (目标: 97%+) {\"✓\" if acc >= 0.97 else \"\"}')\n",
    "    print(f'AUC分数: {auc_score:.3f}')\n",
    "    print(f'最优阈值: {threshold:.3f}')\n",
    "    print(f'特征提取: {extract_time:.1f} ms/张')\n",
    "    print(f'数据库搜索(100人): {search_time:.2f} ms')\n",
    "    print(f'{\"=\"*60}')\n",
    "else:\n",
    "    print('跳过评估：模型未加载')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10.项目总结\n",
    "\n",
    "### 项目完成度检查\n",
    "\n",
    "| 要求项 | 状态 | 实现说明 |\n",
    "|--------|------|----------|\n",
    "| **数据准备** | ✓ | LFW数据集 |\n",
    "| 人脸检测与对齐 | ✓ | MTCNN |\n",
    "| 图像尺寸160×160 | ✓ | Config配置 |\n",
    "| 数据增强(≥3种) | ✓ | 翻转/旋转/颜色抖动/平移/模糊 |\n",
    "| **模型实现** | ✓ | - |\n",
    "| Inception ResNet v1 | ✓ | facenet-pytorch |\n",
    "| 128维嵌入向量 | ✓ | embedding层 |\n",
    "| 三元组损失 | ✓ | TripletLoss |\n",
    "| 硬负样本挖掘 | ✓ | TripletLossHardMining |\n",
    "| 学习率调度 | ✓ | CosineAnnealing |\n",
    "| 预训练微调 | ✓ | vggface2权重 |\n",
    "| **系统功能** | ✓ | - |\n",
    "| 人脸注册 | ✓ | FaceDatabase |\n",
    "| 人脸识别 | ✓ | FaceRecognizer |\n",
    "| 人脸验证 | ✓ | FaceVerifier |\n",
    "| **评估分析** | ✓ | - |\n",
    "| LFW准确率 | ✓ | evaluate_model |\n",
    "| 时间效率 | ✓ | measure_efficiency |\n",
    "| ROC曲线 | ✓ | 可视化输出 |\n",
    "| **加分项** | ✓ | - |\n",
    "| 多人脸检测与识别 | ✓ | MultiFaceRecognizer |\n",
    "\n",
    "### 技术栈\n",
    "- **深度学习框架**: PyTorch\n",
    "- **人脸检测**: MTCNN (支持多人脸)\n",
    "- **骨干网络**: Inception ResNet v1\n",
    "- **损失函数**: Triplet Loss (支持硬负样本挖掘)\n",
    "- **嵌入维度**: 128维\n",
    "\n",
    "### 文件结构\n",
    "```\n",
    "facenet/\n",
    "├── facenet_project.ipynb       # 主项目Notebook\n",
    "├── requirements.txt            # 依赖文件\n",
    "├── lfw/                        # LFW数据集\n",
    "└── output/                     # 所有输出文件\n",
    "    ├── checkpoints/            # 模型检查点\n",
    "    │   ├── facenet_best.pth    # 最优模型\n",
    "    │   └── facenet_ep*.pth     # 各轮次模型\n",
    "    ├── cache/                  # 数据缓存\n",
    "    │   └── lfw_cache.pkl       # 预处理人脸缓存\n",
    "    ├── database/               # 人脸数据库\n",
    "    │   └── face_database.pkl   # 注册人员特征\n",
    "    └── results/                # 评估结果\n",
    "        ├── loss_curve.png      # 训练损失曲线\n",
    "        ├── evaluation_results.png  # ROC曲线等\n",
    "        ├── multi_face_result.png   # 多人脸识别结果\n",
    "        └── multi_face_test.jpg     # 多人脸测试图\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 多人脸检测与识别类（加分项）\n",
    "# ============================================================\n",
    "import cv2\n",
    "\n",
    "class MultiFaceRecognizer:\n",
    "    \"\"\"\n",
    "    多人脸检测与识别器\n",
    "    \n",
    "    功能：\n",
    "    在单张图像中检测并识别多个人脸\n",
    "    \n",
    "    与FaceRecognizer的区别：\n",
    "    - FaceRecognizer: 假设图像中只有一张人脸\n",
    "    - MultiFaceRecognizer: 支持检测和识别多张人脸\n",
    "    \n",
    "    实现关键：\n",
    "    使用MTCNN的keep_all=True选项，保留检测到的所有人脸\n",
    "    \n",
    "    应用场景：\n",
    "    - 合影照片的人物标注\n",
    "    - 监控视频中的多人追踪\n",
    "    - 会议签到系统\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, database, threshold=0.6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: FaceNet模型\n",
    "            database: FaceDatabase实例\n",
    "            threshold: 识别阈值\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.db = database\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # 创建MTCNN检测器，启用多人脸检测模式\n",
    "        self.mtcnn = MTCNN(\n",
    "            image_size=cfg.IMAGE_SIZE,\n",
    "            margin=20,\n",
    "            keep_all=True,  # 关键参数：保留所有检测到的人脸\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "    def detect_faces(self, image):\n",
    "        \"\"\"\n",
    "        检测图像中的所有人脸\n",
    "        \n",
    "        Args:\n",
    "            image: PIL Image 或 numpy数组（BGR格式）\n",
    "        \n",
    "        Returns:\n",
    "            faces: 人脸tensor列表，形状[N, 3, 160, 160]\n",
    "            boxes: 边界框数组，形状[N, 4]，格式为[x1, y1, x2, y2]\n",
    "            probs: 检测概率数组，形状[N]\n",
    "        \"\"\"\n",
    "        # 如果输入是OpenCV格式（BGR numpy数组），转换为PIL Image\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # 检测人脸边界框和概率\n",
    "        boxes, probs = self.mtcnn.detect(image)\n",
    "        \n",
    "        if boxes is None:\n",
    "            return None, None, None\n",
    "        \n",
    "        # 提取对齐后的人脸图像\n",
    "        faces = self.mtcnn(image)\n",
    "        \n",
    "        return faces, boxes, probs\n",
    "    \n",
    "    def recognize_all(self, image_path):\n",
    "        \"\"\"\n",
    "        检测并识别图像中的所有人脸\n",
    "        \n",
    "        Args:\n",
    "            image_path: 图像文件路径\n",
    "        \n",
    "        Returns:\n",
    "            results: 结果列表，每个元素为字典：\n",
    "                {\n",
    "                    'name': 人物姓名或'Unknown',\n",
    "                    'confidence': 置信度,\n",
    "                    'distance': 与最近人物的距离,\n",
    "                    'box': 边界框[x1, y1, x2, y2],\n",
    "                    'detection_prob': 人脸检测概率\n",
    "                }\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # 读取图像\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # 检测所有人脸\n",
    "        faces, boxes, probs = self.detect_faces(img)\n",
    "        \n",
    "        if faces is None:\n",
    "            return []\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # 将所有人脸移至GPU并批量提取特征\n",
    "        faces = faces.to(device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.model(faces)\n",
    "        embeddings = embeddings.cpu().numpy()\n",
    "        \n",
    "        # 对每张人脸进行识别\n",
    "        for i, (emb, box, prob) in enumerate(zip(embeddings, boxes, probs)):\n",
    "            min_dist, best_name = float('inf'), 'Unknown'\n",
    "            \n",
    "            # 在数据库中搜索最相似的人物\n",
    "            for name, db_embs in self.db.db.items():\n",
    "                dists = np.linalg.norm(db_embs - emb, axis=1)\n",
    "                d = dists.min()\n",
    "                if d < min_dist:\n",
    "                    min_dist, best_name = d, name\n",
    "            \n",
    "            # 距离超过阈值则标记为Unknown\n",
    "            if min_dist > self.threshold:\n",
    "                best_name = 'Unknown'\n",
    "            \n",
    "            # 计算置信度\n",
    "            confidence = max(0, 1 - min_dist / 2)\n",
    "            \n",
    "            results.append({\n",
    "                'name': best_name,\n",
    "                'confidence': confidence,\n",
    "                'distance': min_dist,\n",
    "                'box': box.astype(int),\n",
    "                'detection_prob': prob\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize(self, image_path, save_path=None):\n",
    "        \"\"\"\n",
    "        检测识别并可视化结果\n",
    "        \n",
    "        在图像上绘制边界框和识别结果\n",
    "        \n",
    "        Args:\n",
    "            image_path: 输入图像路径\n",
    "            save_path: 输出图像保存路径\n",
    "        \n",
    "        Returns:\n",
    "            results: 识别结果列表\n",
    "        \"\"\"\n",
    "        # 使用OpenCV读取图像（用于绘制）\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 执行识别\n",
    "        results = self.recognize_all(image_path)\n",
    "        \n",
    "        if not results:\n",
    "            print('未检测到人脸')\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(img_rgb)\n",
    "            plt.title('No faces detected')\n",
    "            plt.axis('off')\n",
    "            if save_path:\n",
    "                plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            if save_path:\n",
    "                display_image(save_path)\n",
    "            return results\n",
    "        \n",
    "        # 为每个人脸分配不同颜色\n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, 10))[:, :3] * 255\n",
    "        \n",
    "        # 在图像上绘制边界框和标签\n",
    "        for i, res in enumerate(results):\n",
    "            box = res['box']\n",
    "            name = res['name']\n",
    "            conf = res['confidence']\n",
    "            color = tuple(map(int, colors[i % len(colors)]))\n",
    "            \n",
    "            # 绘制边界框\n",
    "            cv2.rectangle(img_rgb, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "            \n",
    "            # 绘制标签背景和文字\n",
    "            label = f\"{name} ({conf:.1%})\"\n",
    "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            cv2.rectangle(img_rgb, (box[0], box[1]-25), (box[0]+w+5, box[1]), color, -1)\n",
    "            cv2.putText(img_rgb, label, (box[0]+2, box[1]-8),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # 使用matplotlib显示结果\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f'Multi-Face Recognition: {len(results)} faces detected')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f'结果已保存: {save_path}')\n",
    "            display_image(save_path)\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "        # 打印识别结果摘要\n",
    "        print(f'\\n检测到 {len(results)} 张人脸:')\n",
    "        print('-' * 50)\n",
    "        for i, res in enumerate(results, 1):\n",
    "            print(f\"{i}. {res['name']}: 置信度={res['confidence']:.1%}, \"\n",
    "                  f\"距离={res['distance']:.3f}, 检测概率={res['detection_prob']:.1%}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "print('MultiFaceRecognizer 类定义完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 多人脸识别功能测试\n",
    "# ============================================================\n",
    "\n",
    "# 创建多人脸识别器实例\n",
    "multi_recognizer = MultiFaceRecognizer(model, face_db, cfg.THRESHOLD)\n",
    "\n",
    "# 从LFW获取测试图片\n",
    "# 注意：由于使用了缓存版数据集，samples中存储的是tensor而非路径\n",
    "# 因此需要从原始目录获取图片路径\n",
    "test_person = [\n",
    "    d for d in os.listdir(cfg.DATA_ROOT) \n",
    "    if os.path.isdir(os.path.join(cfg.DATA_ROOT, d))\n",
    "][0]  # 取第一个人物\n",
    "\n",
    "test_folder = os.path.join(cfg.DATA_ROOT, test_person)\n",
    "test_img_path = os.path.join(test_folder, os.listdir(test_folder)[0])\n",
    "\n",
    "print(f'测试图像: {test_img_path}')\n",
    "\n",
    "# 运行多人脸识别并保存结果\n",
    "results = multi_recognizer.visualize(test_img_path, save_path=cfg.MULTI_FACE_PATH)\n",
    "print(f'结果已保存: {cfg.MULTI_FACE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 创建多人脸测试图像\n",
    "# ============================================================\n",
    "def create_multi_face_image(registered_persons, n_unknown=2, save_path=None):\n",
    "    \"\"\"\n",
    "    创建包含已注册和未注册人脸的测试图像\n",
    "    \n",
    "    通过拼接多个单人照片来模拟合影场景\n",
    "    用于测试多人脸识别功能\n",
    "    \n",
    "    Args:\n",
    "        registered_persons: 已注册人员名单\n",
    "        n_unknown: 未注册人员数量（用于测试Unknown识别）\n",
    "        save_path: 保存路径\n",
    "    \n",
    "    Returns:\n",
    "        保存的图像路径\n",
    "    \"\"\"\n",
    "    save_path = save_path or f'{cfg.RESULTS_DIR}/multi_face_test.jpg'\n",
    "    \n",
    "    # 获取所有人物目录\n",
    "    all_persons = [\n",
    "        d for d in os.listdir(cfg.DATA_ROOT) \n",
    "        if os.path.isdir(os.path.join(cfg.DATA_ROOT, d))\n",
    "    ]\n",
    "    \n",
    "    # 选择2个已注册的人（测试正确识别）\n",
    "    registered_in_db = [p for p in registered_persons if p in all_persons][:2]\n",
    "    \n",
    "    # 选择n_unknown个未注册的人（测试Unknown识别）\n",
    "    unregistered = [p for p in all_persons if p not in registered_persons]\n",
    "    unknown_persons = random.sample(unregistered, min(n_unknown, len(unregistered)))\n",
    "    \n",
    "    selected_persons = registered_in_db + unknown_persons\n",
    "    \n",
    "    print(f'已注册人员: {registered_in_db}')\n",
    "    print(f'未注册人员: {unknown_persons}')\n",
    "    \n",
    "    # 收集选中人物的照片\n",
    "    images = []\n",
    "    for person in selected_persons:\n",
    "        person_folder = os.path.join(cfg.DATA_ROOT, person)\n",
    "        img_files = [\n",
    "            f for f in os.listdir(person_folder) \n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "        ]\n",
    "        if img_files:\n",
    "            img_path = os.path.join(person_folder, img_files[0])\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((200, 200))  # 统一尺寸\n",
    "            images.append(np.array(img))\n",
    "    \n",
    "    if not images:\n",
    "        print('错误：没有找到测试图片')\n",
    "        return None\n",
    "    \n",
    "    # 创建拼接画布（2行N列）\n",
    "    rows = 2\n",
    "    cols = (len(images) + 1) // 2\n",
    "    h, w = 200, 200\n",
    "    canvas = np.ones((rows * h, cols * w, 3), dtype=np.uint8) * 255  # 白色背景\n",
    "    \n",
    "    # 将图片放置到画布上\n",
    "    for i, img in enumerate(images):\n",
    "        r, c = i // cols, i % cols\n",
    "        canvas[r*h:(r+1)*h, c*w:(c+1)*w] = img\n",
    "    \n",
    "    # 保存拼接图像\n",
    "    Image.fromarray(canvas).save(save_path)\n",
    "    print(f'多人脸测试图像已创建: {save_path}')\n",
    "    display_image(save_path, width=400)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 创建测试图像并运行多人脸识别\n",
    "# ============================================================\n",
    "\n",
    "# 获取已注册人员名单\n",
    "registered_names = list(face_db.db.keys())\n",
    "print(f'已注册人员: {registered_names}')\n",
    "\n",
    "# 创建多人脸测试图像（2个已注册 + 2个未注册）\n",
    "multi_test_path = create_multi_face_image(registered_names, n_unknown=2)\n",
    "\n",
    "# 在测试图像上运行多人脸识别\n",
    "if multi_test_path:\n",
    "    print('\\n测试多人脸识别:')\n",
    "    multi_detection_path = f'{cfg.RESULTS_DIR}/multi_face_detection_result.png'\n",
    "    results = multi_recognizer.visualize(multi_test_path, save_path=multi_detection_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多人脸识别API使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 多人脸识别 API 使用示例\n",
    "# ============================================================\n",
    "# 本示例展示如何在实际应用中调用多人脸识别API\n",
    "\n",
    "# 定义测试图像路径\n",
    "demo_image = f'{cfg.RESULTS_DIR}/multi_face_test.jpg'\n",
    "\n",
    "if os.path.exists(demo_image):\n",
    "    # ==============================\n",
    "    # API调用方式1：只获取识别结果\n",
    "    # ==============================\n",
    "    results = multi_recognizer.recognize_all(demo_image)\n",
    "    \n",
    "    print('=== API调用示例 ===')\n",
    "    print(f'输入图像: {demo_image}')\n",
    "    print(f'检测到 {len(results)} 张人脸\\n')\n",
    "    \n",
    "    # 遍历每个检测到的人脸\n",
    "    for i, res in enumerate(results, 1):\n",
    "        print(f'人脸 #{i}:')\n",
    "        print(f\"  姓名: {res['name']}\")\n",
    "        print(f\"  置信度: {res['confidence']:.1%}\")\n",
    "        print(f\"  距离: {res['distance']:.3f}\")\n",
    "        print(f\"  边界框: {res['box'].tolist()}\")  # [x1, y1, x2, y2]\n",
    "        print(f\"  检测概率: {res['detection_prob']:.1%}\")\n",
    "        print('-' * 30)\n",
    "    \n",
    "    # ==============================\n",
    "    # API调用方式2：获取结果并可视化\n",
    "    # ==============================\n",
    "    print('\\n生成可视化结果...')\n",
    "    api_demo_path = f'{cfg.RESULTS_DIR}/api_demo_result.png'\n",
    "    multi_recognizer.visualize(demo_image, save_path=api_demo_path)\n",
    "    \n",
    "    # ==============================\n",
    "    # 实际应用代码示例\n",
    "    # ==============================\n",
    "    \"\"\"\n",
    "    # 在实际项目中的使用示例：\n",
    "    \n",
    "    # 1. 初始化（程序启动时执行一次）\n",
    "    model = FaceNet('vggface2', 128).to(device)\n",
    "    face_db = FaceDatabase(model)\n",
    "    face_db.load('my_database.pkl')\n",
    "    recognizer = MultiFaceRecognizer(model, face_db, threshold=0.6)\n",
    "    \n",
    "    # 2. 处理用户上传的图片\n",
    "    def handle_upload(image_path):\n",
    "        results = recognizer.recognize_all(image_path)\n",
    "        return [\n",
    "            {\n",
    "                'name': r['name'],\n",
    "                'confidence': r['confidence'],\n",
    "                'bbox': r['box'].tolist()\n",
    "            }\n",
    "            for r in results\n",
    "        ]\n",
    "    \n",
    "    # 3. 返回JSON响应\n",
    "    response = handle_upload('user_upload.jpg')\n",
    "    \"\"\"\n",
    "    \n",
    "else:\n",
    "    print('请先运行前面的单元格生成测试图片')\n",
    "    print(f'预期路径: {demo_image}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
