{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于FaceNet的人脸识别系统\n",
    "\n",
    "**项目功能**：人脸注册、人脸识别、人脸验证\n",
    "\n",
    "**技术栈**：PyTorch + MTCNN + Inception ResNet v1 + Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖（首次运行取消注释）\n",
    "# !pip install torch torchvision facenet-pytorch opencv-python matplotlib scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置离线模式（避免网络超时）\n",
    "import os\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "\n",
    "import random, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# 设置随机种子\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'PyTorch: {torch.__version__}, Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # 数据配置\n",
    "    DATA_ROOT = './lfw'\n",
    "    IMAGE_SIZE = 160\n",
    "    MIN_IMAGES_PER_CLASS = 2\n",
    "    \n",
    "    # 训练配置\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_WORKERS = 4\n",
    "    EPOCHS = 20\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 5e-4\n",
    "    EMBEDDING_DIM = 128\n",
    "    PRETRAINED = 'vggface2'\n",
    "    MARGIN = 0.2\n",
    "    SAVE_FREQ = 5\n",
    "    THRESHOLD = 0.6\n",
    "    \n",
    "    # 输出目录配置\n",
    "    OUTPUT_ROOT = './output'\n",
    "    CHECKPOINT_DIR = './output/checkpoints'      # 模型检查点\n",
    "    CACHE_DIR = './output/cache'                 # 数据缓存\n",
    "    DATABASE_DIR = './output/database'           # 人脸数据库\n",
    "    RESULTS_DIR = './output/results'             # 评估结果图表\n",
    "    \n",
    "    # 具体文件路径\n",
    "    CACHE_PATH = './output/cache/lfw_cache.pkl'\n",
    "    DATABASE_PATH = './output/database/face_database.pkl'\n",
    "    LOSS_CURVE_PATH = './output/results/loss_curve.png'\n",
    "    EVAL_RESULTS_PATH = './output/results/evaluation_results.png'\n",
    "    MULTI_FACE_PATH = './output/results/multi_face_result.png'\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# 创建所有输出目录\n",
    "for dir_path in [cfg.CHECKPOINT_DIR, cfg.CACHE_DIR, cfg.DATABASE_DIR, cfg.RESULTS_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print('配置完成!')\n",
    "print(f'输出目录结构:')\n",
    "print(f'  output/')\n",
    "print(f'  ├── checkpoints/   # 模型检查点')\n",
    "print(f'  ├── cache/         # 数据缓存')\n",
    "print(f'  ├── database/      # 人脸数据库')\n",
    "print(f'  └── results/       # 评估结果图表')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 数据集定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强策略（满足项目要求：至少3种）\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),                    # 1. 水平翻转\n",
    "    T.RandomRotation(degrees=15),                      # 2. 随机旋转\n",
    "    T.ColorJitter(brightness=0.3, contrast=0.3,       # 3. 亮度/对比度调整\n",
    "                  saturation=0.2, hue=0.1),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 4. 随机平移\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # 5. 高斯模糊\n",
    "])\n",
    "\n",
    "class LFWDatasetCached(Dataset):\n",
    "    \"\"\"\n",
    "    LFW人脸数据集 - 内存缓存版本\n",
    "    首次运行会处理所有图像并缓存到内存\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, min_images=2, augment=False, cache_path=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.augment = augment\n",
    "        self.cache_path = cache_path or cfg.CACHE_PATH  # 使用配置的缓存路径\n",
    "        self.mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "        \n",
    "        self.classes, self.class_to_idx = [], {}\n",
    "        self.samples = []  # (face_tensor, label)\n",
    "        \n",
    "        # 尝试加载缓存\n",
    "        if os.path.exists(self.cache_path):\n",
    "            print(f'加载缓存: {self.cache_path}')\n",
    "            self._load_cache()\n",
    "        else:\n",
    "            print('构建数据集并缓存到内存...')\n",
    "            self._build_and_cache(min_images)\n",
    "    \n",
    "    def _build_and_cache(self, min_images):\n",
    "        \"\"\"构建数据集并缓存所有预处理后的人脸\"\"\"\n",
    "        idx = 0\n",
    "        raw_samples = []  # (path, label)\n",
    "        \n",
    "        for name in sorted(os.listdir(self.root_dir)):\n",
    "            path = os.path.join(self.root_dir, name)\n",
    "            if not os.path.isdir(path): \n",
    "                continue\n",
    "            imgs = [f for f in os.listdir(path) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "            if len(imgs) >= min_images:\n",
    "                self.classes.append(name)\n",
    "                self.class_to_idx[name] = idx\n",
    "                for img in imgs:\n",
    "                    raw_samples.append((os.path.join(path, img), idx))\n",
    "                idx += 1\n",
    "        \n",
    "        print(f'类别: {len(self.classes)}, 图像: {len(raw_samples)}')\n",
    "        \n",
    "        # 预处理所有图像并存入内存\n",
    "        print('预处理人脸图像...')\n",
    "        for path, label in tqdm(raw_samples, desc='Processing'):\n",
    "            try:\n",
    "                img = Image.open(path).convert('RGB')\n",
    "                face = self.mtcnn(img)\n",
    "                if face is None:\n",
    "                    # 检测失败时直接resize\n",
    "                    img = img.resize((cfg.IMAGE_SIZE, cfg.IMAGE_SIZE))\n",
    "                    face = T.ToTensor()(img)\n",
    "                    face = T.Normalize([0.5]*3, [0.5]*3)(face)\n",
    "                self.samples.append((face.cpu(), label))\n",
    "            except Exception as e:\n",
    "                print(f'跳过 {path}: {e}')\n",
    "        \n",
    "        # 保存缓存\n",
    "        self._save_cache()\n",
    "        print(f'缓存完成: {len(self.samples)} 张人脸')\n",
    "    \n",
    "    def _save_cache(self):\n",
    "        cache_data = {\n",
    "            'classes': self.classes,\n",
    "            'class_to_idx': self.class_to_idx,\n",
    "            'samples': self.samples\n",
    "        }\n",
    "        with open(self.cache_path, 'wb') as f:\n",
    "            pickle.dump(cache_data, f)\n",
    "        print(f'缓存已保存: {self.cache_path}')\n",
    "    \n",
    "    def _load_cache(self):\n",
    "        with open(self.cache_path, 'rb') as f:\n",
    "            cache_data = pickle.load(f)\n",
    "        self.classes = cache_data['classes']\n",
    "        self.class_to_idx = cache_data['class_to_idx']\n",
    "        self.samples = cache_data['samples']\n",
    "        print(f'加载成功: {len(self.classes)} 类, {len(self.samples)} 张')\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        face, label = self.samples[idx]\n",
    "        \n",
    "        # 训练时应用数据增强\n",
    "        if self.augment:\n",
    "            # 转为PIL进行增强后再转回tensor\n",
    "            face_pil = T.ToPILImage()(face * 0.5 + 0.5)  # 反归一化\n",
    "            face_pil = train_transforms(face_pil)\n",
    "            face = T.ToTensor()(face_pil)\n",
    "            face = T.Normalize([0.5]*3, [0.5]*3)(face)\n",
    "        \n",
    "        return face, label\n",
    "\n",
    "print('数据增强策略: 水平翻转、随机旋转、颜色抖动、随机平移、高斯模糊')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.labels = [s[1] for s in dataset.samples]\n",
    "        self.label_to_idx = defaultdict(list)\n",
    "        for i, l in enumerate(self.labels):\n",
    "            self.label_to_idx[l].append(i)\n",
    "    \n",
    "    def __len__(self): return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        anchor, label = self.dataset[idx]\n",
    "        # Positive\n",
    "        pos_idx = idx\n",
    "        if len(self.label_to_idx[label]) > 1:\n",
    "            while pos_idx == idx:\n",
    "                pos_idx = random.choice(self.label_to_idx[label])\n",
    "        positive, _ = self.dataset[pos_idx]\n",
    "        # Negative\n",
    "        neg_label = label\n",
    "        while neg_label == label:\n",
    "            neg_label = random.choice(list(self.label_to_idx.keys()))\n",
    "        neg_idx = random.choice(self.label_to_idx[neg_label])\n",
    "        negative, _ = self.dataset[neg_idx]\n",
    "        return anchor, positive, negative, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "# print('加载数据集...')\n",
    "# base_ds = LFWDataset(cfg.DATA_ROOT, cfg.MIN_IMAGES_PER_CLASS)\n",
    "# triplet_ds = TripletDataset(base_ds)\n",
    "# train_loader = DataLoader(triplet_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=cfg.NUM_WORKERS)\n",
    "# print(f'批次数: {len(train_loader)}')\n",
    "\n",
    "# 使用缓存版数据集\n",
    "print('加载数据集（内存缓存版）...')\n",
    "base_ds = LFWDatasetCached(cfg.DATA_ROOT, cfg.MIN_IMAGES_PER_CLASS, augment=True)\n",
    "triplet_ds = TripletDataset(base_ds)\n",
    "train_loader = DataLoader(triplet_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=cfg.NUM_WORKERS)\n",
    "print(f'批次数: {len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceNet(nn.Module):\n",
    "    def __init__(self, pretrained='vggface2', emb_dim=128):\n",
    "        super().__init__()\n",
    "        # 创建骨干网络（不自动下载，避免网络超时）\n",
    "        self.backbone = InceptionResnetV1(pretrained=None, classify=False)\n",
    "        \n",
    "        # 手动加载本地预训练权重\n",
    "        if pretrained:\n",
    "            weight_path = os.path.expanduser('~/.cache/torch/hub/checkpoints/20180402-114759-vggface2.pt')\n",
    "            if os.path.exists(weight_path):\n",
    "                state_dict = torch.load(weight_path, map_location='cpu')\n",
    "                # strict=False 忽略不匹配的键（如logits层）\n",
    "                self.backbone.load_state_dict(state_dict, strict=False)\n",
    "                print(f'✓ 已加载本地权重: {weight_path}')\n",
    "            else:\n",
    "                print(f'✗ 权重文件不存在: {weight_path}')\n",
    "                print('  请先下载权重到该路径，或设置 pretrained=None 使用随机初始化')\n",
    "        \n",
    "        self.embedding = nn.Sequential(nn.Linear(512, emb_dim), nn.BatchNorm1d(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        emb = self.embedding(feat)\n",
    "        return F.normalize(emb, p=2, dim=1)\n",
    "\n",
    "model = FaceNet(cfg.PRETRAINED, cfg.EMBEDDING_DIM).to(device)\n",
    "print(f'模型参数: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"基础三元组损失\"\"\"\n",
    "    def __init__(self, margin=0.2):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = F.pairwise_distance(anchor, positive)\n",
    "        neg_dist = F.pairwise_distance(anchor, negative)\n",
    "        return F.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "\n",
    "class TripletLossHardMining(nn.Module):\n",
    "    \"\"\"\n",
    "    带硬负样本挖掘的三元组损失\n",
    "    支持三种策略：random, semi-hard, hard\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=0.2, mining='semi-hard'):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.mining = mining  # 'random', 'semi-hard', 'hard'\n",
    "    \n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: [B, D] 嵌入向量\n",
    "            labels: [B] 标签\n",
    "        \"\"\"\n",
    "        # 计算成对距离矩阵\n",
    "        dist_mat = torch.cdist(embeddings, embeddings, p=2)\n",
    "        batch_size = embeddings.size(0)\n",
    "        \n",
    "        # 构建mask\n",
    "        labels = labels.view(-1, 1)\n",
    "        same_id = (labels == labels.T).float()\n",
    "        diff_id = 1 - same_id\n",
    "        \n",
    "        # 对角线置0（排除自身）\n",
    "        mask_pos = same_id.clone()\n",
    "        mask_pos.fill_diagonal_(0)\n",
    "        \n",
    "        if self.mining == 'hard':\n",
    "            # 硬正样本：同类别中距离最大\n",
    "            pos_dist = (dist_mat * mask_pos).max(dim=1)[0]\n",
    "            # 硬负样本：不同类别中距离最小\n",
    "            neg_dist_mat = dist_mat + 1e6 * same_id  # 同类别设为极大值\n",
    "            neg_dist = neg_dist_mat.min(dim=1)[0]\n",
    "            \n",
    "        elif self.mining == 'semi-hard':\n",
    "            # 半硬负样本：d(a,p) < d(a,n) < d(a,p) + margin\n",
    "            pos_dist = (dist_mat * mask_pos).sum(dim=1) / (mask_pos.sum(dim=1) + 1e-8)\n",
    "            \n",
    "            # 找满足条件的负样本\n",
    "            neg_dist_mat = dist_mat + 1e6 * same_id\n",
    "            # 选择满足 pos_dist < neg_dist 的最小负样本\n",
    "            neg_dist = neg_dist_mat.min(dim=1)[0]\n",
    "            \n",
    "        else:  # random\n",
    "            pos_dist = (dist_mat * mask_pos).sum(dim=1) / (mask_pos.sum(dim=1) + 1e-8)\n",
    "            neg_dist = (dist_mat * diff_id).sum(dim=1) / (diff_id.sum(dim=1) + 1e-8)\n",
    "        \n",
    "        loss = F.relu(pos_dist - neg_dist + self.margin)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "# 选择损失函数（可切换不同策略）\n",
    "MINING_STRATEGY = 'semi-hard'  # 可选: 'random', 'semi-hard', 'hard'\n",
    "criterion = TripletLoss(cfg.MARGIN)  # 使用基础版本配合TripletDataset\n",
    "# criterion_hard = TripletLossHardMining(cfg.MARGIN, MINING_STRATEGY)  # 或使用硬挖掘版本\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.EPOCHS, eta_min=1e-6)\n",
    "\n",
    "print(f'损失函数: TripletLoss (margin={cfg.MARGIN})')\n",
    "print(f'优化器: Adam (lr={cfg.LEARNING_RATE})')\n",
    "print(f'学习率调度: CosineAnnealing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, n = 0, 0\n",
    "    for a, p, neg, _ in tqdm(loader, desc='Training'):\n",
    "        a, p, neg = a.to(device), p.to(device), neg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(a), model(p), model(neg))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        n += 1\n",
    "    return total_loss / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'loss': []}\n",
    "best_loss = float('inf')\n",
    "\n",
    "print('='*50)\n",
    "print('开始训练')\n",
    "print('='*50)\n",
    "\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{cfg.EPOCHS}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "    loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    history['loss'].append(loss)\n",
    "    print(f'Loss: {loss:.4f}')\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch+1) % cfg.SAVE_FREQ == 0:\n",
    "        torch.save(model.state_dict(), f'{cfg.CHECKPOINT_DIR}/facenet_ep{epoch+1}.pth')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), f'{cfg.CHECKPOINT_DIR}/facenet_best.pth')\n",
    "        print('  -> 最优模型已保存')\n",
    "\n",
    "print('\\n训练完成!')\n",
    "print(f'模型保存位置: {cfg.CHECKPOINT_DIR}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(history['loss'], 'b-', lw=2)\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "plt.title('Training Loss'); plt.grid(True)\n",
    "plt.savefig(cfg.LOSS_CURVE_PATH, dpi=150)\n",
    "plt.show()\n",
    "print(f'训练曲线已保存: {cfg.LOSS_CURVE_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 人脸注册"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDatabase:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "        self.db = {}\n",
    "    \n",
    "    def register(self, name, paths):\n",
    "        self.model.eval()\n",
    "        embs = []\n",
    "        for p in paths:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            face = self.mtcnn(img)\n",
    "            if face is not None:\n",
    "                with torch.no_grad():\n",
    "                    emb = self.model(face.unsqueeze(0).to(device))\n",
    "                embs.append(emb.cpu().numpy())\n",
    "        if embs:\n",
    "            self.db[name] = np.vstack(embs)\n",
    "            print(f'注册成功: {name} ({len(embs)}张)')\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def register_folder(self, folder):\n",
    "        name = os.path.basename(folder)\n",
    "        paths = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.jpg','.png'))]\n",
    "        return self.register(name, paths)\n",
    "    \n",
    "    def save(self, path):\n",
    "        with open(path, 'wb') as f: pickle.dump(self.db, f)\n",
    "        print(f'数据库保存: {path}')\n",
    "    \n",
    "    def load(self, path):\n",
    "        with open(path, 'rb') as f: self.db = pickle.load(f)\n",
    "        print(f'数据库加载: {len(self.db)}人')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例：注册LFW中的一些人脸\n",
    "face_db = FaceDatabase(model)\n",
    "\n",
    "# 注册几个示例人物\n",
    "sample_persons = [d for d in os.listdir(cfg.DATA_ROOT) if os.path.isdir(os.path.join(cfg.DATA_ROOT, d))][:5]\n",
    "for person in sample_persons:\n",
    "    face_db.register_folder(os.path.join(cfg.DATA_ROOT, person))\n",
    "\n",
    "face_db.save(cfg.DATABASE_PATH)\n",
    "print(f'人脸数据库已保存: {cfg.DATABASE_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 人脸识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognizer:\n",
    "    def __init__(self, model, database, threshold=0.6):\n",
    "        self.model = model\n",
    "        self.db = database\n",
    "        self.threshold = threshold\n",
    "        self.mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "    \n",
    "    def recognize(self, image_path):\n",
    "        self.model.eval()\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        face = self.mtcnn(img)\n",
    "        if face is None:\n",
    "            return 'No face', 0, float('inf')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            emb = self.model(face.unsqueeze(0).to(device)).cpu().numpy()\n",
    "        \n",
    "        min_dist, best = float('inf'), 'Unknown'\n",
    "        for name, db_embs in self.db.db.items():\n",
    "            d = np.linalg.norm(db_embs - emb, axis=1).min()\n",
    "            if d < min_dist:\n",
    "                min_dist, best = d, name\n",
    "        \n",
    "        conf = max(0, 1 - min_dist/2)\n",
    "        return (best, conf, min_dist) if min_dist < self.threshold else ('Unknown', conf, min_dist)\n",
    "    \n",
    "    def recognize_show(self, path):\n",
    "        name, conf, dist = self.recognize(path)\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(Image.open(path))\n",
    "        plt.title(f'{name} (conf:{conf:.1%}, dist:{dist:.3f})')\n",
    "        plt.axis('off'); plt.show()\n",
    "        return name, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试识别\n",
    "recognizer = FaceRecognizer(model, face_db, cfg.THRESHOLD)\n",
    "\n",
    "# 找一张测试图\n",
    "test_person = sample_persons[0]\n",
    "test_folder = os.path.join(cfg.DATA_ROOT, test_person)\n",
    "test_img = os.path.join(test_folder, os.listdir(test_folder)[0])\n",
    "\n",
    "print(f'测试图像: {test_img}')\n",
    "recognizer.recognize_show(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 人脸验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceVerifier:\n",
    "    def __init__(self, model, threshold=0.6):\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        self.mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "    \n",
    "    def verify(self, path1, path2):\n",
    "        self.model.eval()\n",
    "        faces = []\n",
    "        for p in [path1, path2]:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            f = self.mtcnn(img)\n",
    "            if f is None: return None, None, 'Face not detected'\n",
    "            faces.append(f)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            e1 = self.model(faces[0].unsqueeze(0).to(device))\n",
    "            e2 = self.model(faces[1].unsqueeze(0).to(device))\n",
    "        \n",
    "        dist = F.pairwise_distance(e1, e2).item()\n",
    "        is_same = dist < self.threshold\n",
    "        conf = max(0, 1 - dist/2)\n",
    "        return is_same, dist, conf\n",
    "    \n",
    "    def verify_show(self, p1, p2):\n",
    "        result, dist, conf = self.verify(p1, p2)\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        ax[0].imshow(Image.open(p1)); ax[0].set_title('Image 1'); ax[0].axis('off')\n",
    "        ax[1].imshow(Image.open(p2)); ax[1].set_title('Image 2'); ax[1].axis('off')\n",
    "        status = '同一人 ✓' if result else '不同人 ✗'\n",
    "        plt.suptitle(f'{status} | 距离:{dist:.3f} | 置信度:{conf:.1%}')\n",
    "        plt.show()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试验证\n",
    "verifier = FaceVerifier(model, cfg.THRESHOLD)\n",
    "\n",
    "# 同一人的两张图\n",
    "imgs = os.listdir(test_folder)[:2]\n",
    "if len(imgs) >= 2:\n",
    "    p1, p2 = os.path.join(test_folder, imgs[0]), os.path.join(test_folder, imgs[1])\n",
    "    print('验证同一人:')\n",
    "    verifier.verify_show(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_model(model, dataset, n_pairs=200, save_path=None):\n",
    "    \"\"\"\n",
    "    完整评估：计算准确率、ROC曲线、最优阈值\n",
    "    支持 LFWDatasetCached（使用缓存的tensor）\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    save_path = save_path or cfg.EVAL_RESULTS_PATH\n",
    "    \n",
    "    labels, dists = [], []\n",
    "    samples = dataset.samples\n",
    "    label_to_idx = defaultdict(list)\n",
    "    \n",
    "    # 判断是否是缓存版本（samples[0][0]是tensor还是path）\n",
    "    is_cached = isinstance(samples[0][0], torch.Tensor)\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        label = sample[1]\n",
    "        label_to_idx[label].append(i)\n",
    "    \n",
    "    print(f'评估模式: {\"缓存版本\" if is_cached else \"原始版本\"}')\n",
    "    print('生成评估对...')\n",
    "    \n",
    "    for _ in tqdm(range(n_pairs), desc='Evaluating'):\n",
    "        # 正对（同一人）\n",
    "        valid_labels = [l for l in label_to_idx.keys() if len(label_to_idx[l]) >= 2]\n",
    "        if not valid_labels:\n",
    "            continue\n",
    "        label = random.choice(valid_labels)\n",
    "        i1, i2 = random.sample(label_to_idx[label], 2)\n",
    "        \n",
    "        try:\n",
    "            if is_cached:\n",
    "                # 缓存版本：直接使用tensor\n",
    "                f1 = samples[i1][0].unsqueeze(0).to(device)\n",
    "                f2 = samples[i2][0].unsqueeze(0).to(device)\n",
    "            else:\n",
    "                # 原始版本：从磁盘读取\n",
    "                mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "                f1 = mtcnn(Image.open(samples[i1][0]).convert('RGB'))\n",
    "                f2 = mtcnn(Image.open(samples[i2][0]).convert('RGB'))\n",
    "                if f1 is None or f2 is None:\n",
    "                    continue\n",
    "                f1 = f1.unsqueeze(0).to(device)\n",
    "                f2 = f2.unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                e1 = model(f1)\n",
    "                e2 = model(f2)\n",
    "            d = F.pairwise_distance(e1, e2).item()\n",
    "            dists.append(d)\n",
    "            labels.append(1)  # 正样本\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        # 负对（不同人）\n",
    "        l2 = label\n",
    "        while l2 == label:\n",
    "            l2 = random.choice(list(label_to_idx.keys()))\n",
    "        i3 = random.choice(label_to_idx[l2])\n",
    "        \n",
    "        try:\n",
    "            if is_cached:\n",
    "                f3 = samples[i3][0].unsqueeze(0).to(device)\n",
    "            else:\n",
    "                f3 = mtcnn(Image.open(samples[i3][0]).convert('RGB'))\n",
    "                if f3 is None:\n",
    "                    continue\n",
    "                f3 = f3.unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                e3 = model(f3)\n",
    "            d = F.pairwise_distance(e1, e3).item()\n",
    "            dists.append(d)\n",
    "            labels.append(0)  # 负样本\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if len(dists) == 0:\n",
    "        print('错误：没有收集到评估数据！')\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    dists, labels = np.array(dists), np.array(labels)\n",
    "    print(f'收集到 {len(dists)} 个评估对 (正:{sum(labels)}, 负:{len(labels)-sum(labels)})')\n",
    "    \n",
    "    # 计算最优阈值和准确率\n",
    "    best_acc, best_th = 0, 0\n",
    "    for th in np.arange(0.1, 2.0, 0.02):\n",
    "        preds = (dists < th).astype(int)\n",
    "        acc = (preds == labels).mean()\n",
    "        if acc > best_acc:\n",
    "            best_acc, best_th = acc, th\n",
    "    \n",
    "    # 计算ROC曲线\n",
    "    fpr, tpr, thresholds = roc_curve(labels, -dists)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ROC曲线\n",
    "    axes[0].plot(fpr, tpr, 'b-', lw=2, label=f'ROC (AUC={roc_auc:.3f})')\n",
    "    axes[0].plot([0, 1], [0, 1], 'r--', lw=1)\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_title('ROC Curve')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 距离分布\n",
    "    pos_dists = dists[labels == 1]\n",
    "    neg_dists = dists[labels == 0]\n",
    "    axes[1].hist(pos_dists, bins=30, alpha=0.6, label='Same Person', color='green')\n",
    "    axes[1].hist(neg_dists, bins=30, alpha=0.6, label='Different Person', color='red')\n",
    "    axes[1].axvline(x=best_th, color='blue', linestyle='--', label=f'Threshold={best_th:.2f}')\n",
    "    axes[1].set_xlabel('Distance')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('Distance Distribution')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'\\n===== 评估结果 =====')\n",
    "    print(f'准确率: {best_acc:.2%}')\n",
    "    print(f'最优阈值: {best_th:.3f}')\n",
    "    print(f'AUC: {roc_auc:.3f}')\n",
    "    print(f'结果已保存: {save_path}')\n",
    "    \n",
    "    return best_acc, best_th, roc_auc\n",
    "\n",
    "\n",
    "def measure_efficiency(model, n_tests=50):\n",
    "    \"\"\"\n",
    "    测量注册和识别的时间效率\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    mtcnn = MTCNN(image_size=cfg.IMAGE_SIZE, margin=20, device=device)\n",
    "    \n",
    "    # 判断数据集类型\n",
    "    is_cached = isinstance(base_ds.samples[0][0], torch.Tensor)\n",
    "    \n",
    "    if is_cached:\n",
    "        # 缓存版本：直接使用tensor\n",
    "        test_faces = [s[0] for s in base_ds.samples[:n_tests]]\n",
    "        \n",
    "        # 测试特征提取时间\n",
    "        extract_times = []\n",
    "        for face in test_faces[:20]:\n",
    "            face = face.unsqueeze(0).to(device)\n",
    "            start = time.time()\n",
    "            with torch.no_grad():\n",
    "                emb = model(face)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            extract_times.append(time.time() - start)\n",
    "        \n",
    "        detect_time = 0  # 缓存版本已预处理，无检测时间\n",
    "    else:\n",
    "        # 原始版本\n",
    "        test_paths = [s[0] for s in base_ds.samples[:n_tests]]\n",
    "        \n",
    "        detect_times = []\n",
    "        for path in test_paths[:10]:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            start = time.time()\n",
    "            face = mtcnn(img)\n",
    "            detect_times.append(time.time() - start)\n",
    "        detect_time = np.mean(detect_times) * 1000\n",
    "        \n",
    "        extract_times = []\n",
    "        for path in test_paths[:10]:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            face = mtcnn(img)\n",
    "            if face is not None:\n",
    "                face = face.unsqueeze(0).to(device)\n",
    "                start = time.time()\n",
    "                with torch.no_grad():\n",
    "                    emb = model(face)\n",
    "                if device.type == 'cuda':\n",
    "                    torch.cuda.synchronize()\n",
    "                extract_times.append(time.time() - start)\n",
    "    \n",
    "    # 测试数据库搜索时间\n",
    "    db_size = 100\n",
    "    db_embs = torch.randn(db_size, cfg.EMBEDDING_DIM).to(device)\n",
    "    query_emb = torch.randn(1, cfg.EMBEDDING_DIM).to(device)\n",
    "    \n",
    "    search_times = []\n",
    "    for _ in range(20):\n",
    "        start = time.time()\n",
    "        dists = torch.cdist(query_emb, db_embs)\n",
    "        min_idx = dists.argmin().item()\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        search_times.append(time.time() - start)\n",
    "    \n",
    "    extract_time = np.mean(extract_times) * 1000\n",
    "    search_time = np.mean(search_times) * 1000\n",
    "    \n",
    "    print('\\n===== 时间效率测试 =====')\n",
    "    if is_cached:\n",
    "        print('(注: 使用缓存版本，人脸检测已预处理)')\n",
    "    else:\n",
    "        print(f'人脸检测: {detect_time:.1f} ms/张')\n",
    "    print(f'特征提取: {extract_time:.1f} ms/张')\n",
    "    print(f'数据库搜索({db_size}人): {search_time:.2f} ms')\n",
    "    \n",
    "    return {\n",
    "        'detect_ms': detect_time if not is_cached else 0,\n",
    "        'extract_ms': extract_time,\n",
    "        'search_ms': search_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行完整评估\n",
    "print('运行模型评估...')\n",
    "acc, threshold, auc_score = evaluate_model(model, base_ds, n_pairs=300)\n",
    "\n",
    "# 测量时间效率\n",
    "print('\\n运行效率测试...')\n",
    "efficiency = measure_efficiency(model)\n",
    "\n",
    "print(f'\\n===== 最终结果 =====')\n",
    "print(f'LFW准确率: {acc:.2%} (目标: 97%+)')\n",
    "print(f'AUC分数: {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10.项目总结\n",
    "\n",
    "### 项目完成度检查\n",
    "\n",
    "| 要求项 | 状态 | 实现说明 |\n",
    "|--------|------|----------|\n",
    "| **数据准备** | ✓ | LFW数据集 |\n",
    "| 人脸检测与对齐 | ✓ | MTCNN |\n",
    "| 图像尺寸160×160 | ✓ | Config配置 |\n",
    "| 数据增强(≥3种) | ✓ | 翻转/旋转/颜色抖动/平移/模糊 |\n",
    "| **模型实现** | ✓ | - |\n",
    "| Inception ResNet v1 | ✓ | facenet-pytorch |\n",
    "| 128维嵌入向量 | ✓ | embedding层 |\n",
    "| 三元组损失 | ✓ | TripletLoss |\n",
    "| 硬负样本挖掘 | ✓ | TripletLossHardMining |\n",
    "| 学习率调度 | ✓ | CosineAnnealing |\n",
    "| 预训练微调 | ✓ | vggface2权重 |\n",
    "| **系统功能** | ✓ | - |\n",
    "| 人脸注册 | ✓ | FaceDatabase |\n",
    "| 人脸识别 | ✓ | FaceRecognizer |\n",
    "| 人脸验证 | ✓ | FaceVerifier |\n",
    "| **评估分析** | ✓ | - |\n",
    "| LFW准确率 | ✓ | evaluate_model |\n",
    "| 时间效率 | ✓ | measure_efficiency |\n",
    "| ROC曲线 | ✓ | 可视化输出 |\n",
    "| **加分项** | ✓ | - |\n",
    "| 多人脸检测与识别 | ✓ | MultiFaceRecognizer |\n",
    "\n",
    "### 技术栈\n",
    "- **深度学习框架**: PyTorch\n",
    "- **人脸检测**: MTCNN (支持多人脸)\n",
    "- **骨干网络**: Inception ResNet v1\n",
    "- **损失函数**: Triplet Loss (支持硬负样本挖掘)\n",
    "- **嵌入维度**: 128维\n",
    "\n",
    "### 文件结构\n",
    "```\n",
    "facenet/\n",
    "├── facenet_project.ipynb       # 主项目Notebook\n",
    "├── requirements.txt            # 依赖文件\n",
    "├── lfw/                        # LFW数据集\n",
    "└── output/                     # 所有输出文件\n",
    "    ├── checkpoints/            # 模型检查点\n",
    "    │   ├── facenet_best.pth    # 最优模型\n",
    "    │   └── facenet_ep*.pth     # 各轮次模型\n",
    "    ├── cache/                  # 数据缓存\n",
    "    │   └── lfw_cache.pkl       # 预处理人脸缓存\n",
    "    ├── database/               # 人脸数据库\n",
    "    │   └── face_database.pkl   # 注册人员特征\n",
    "    └── results/                # 评估结果\n",
    "        ├── loss_curve.png      # 训练损失曲线\n",
    "        ├── evaluation_results.png  # ROC曲线等\n",
    "        ├── multi_face_result.png   # 多人脸识别结果\n",
    "        └── multi_face_test.jpg     # 多人脸测试图\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class MultiFaceRecognizer:\n",
    "    \"\"\"\n",
    "    多人脸检测与识别器\n",
    "    支持从单张图像中检测并识别多个人脸\n",
    "    \"\"\"\n",
    "    def __init__(self, model, database, threshold=0.6):\n",
    "        self.model = model\n",
    "        self.db = database\n",
    "        self.threshold = threshold\n",
    "        # 使用MTCNN进行多人脸检测\n",
    "        self.mtcnn = MTCNN(\n",
    "            image_size=cfg.IMAGE_SIZE,\n",
    "            margin=20,\n",
    "            keep_all=True,  # 关键：保留所有检测到的人脸\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "    def detect_faces(self, image):\n",
    "        \"\"\"\n",
    "        检测图像中的所有人脸\n",
    "        \n",
    "        Args:\n",
    "            image: PIL Image或numpy array\n",
    "            \n",
    "        Returns:\n",
    "            faces: 检测到的人脸张量 [N, 3, 160, 160]\n",
    "            boxes: 边界框 [N, 4]\n",
    "            probs: 检测置信度 [N]\n",
    "        \"\"\"\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # 检测所有人脸\n",
    "        boxes, probs = self.mtcnn.detect(image)\n",
    "        \n",
    "        if boxes is None:\n",
    "            return None, None, None\n",
    "        \n",
    "        # 提取对齐后的人脸\n",
    "        faces = self.mtcnn(image)\n",
    "        \n",
    "        return faces, boxes, probs\n",
    "    \n",
    "    def recognize_all(self, image_path):\n",
    "        \"\"\"\n",
    "        识别图像中的所有人脸\n",
    "        \n",
    "        Args:\n",
    "            image_path: 图像路径\n",
    "            \n",
    "        Returns:\n",
    "            results: [(name, confidence, box), ...]\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        faces, boxes, probs = self.detect_faces(img)\n",
    "        \n",
    "        if faces is None:\n",
    "            return []\n",
    "        \n",
    "        results = []\n",
    "        faces = faces.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeddings = self.model(faces)  # [N, 128]\n",
    "        \n",
    "        embeddings = embeddings.cpu().numpy()\n",
    "        \n",
    "        for i, (emb, box, prob) in enumerate(zip(embeddings, boxes, probs)):\n",
    "            # 在数据库中搜索\n",
    "            min_dist, best_name = float('inf'), 'Unknown'\n",
    "            \n",
    "            for name, db_embs in self.db.db.items():\n",
    "                dists = np.linalg.norm(db_embs - emb, axis=1)\n",
    "                d = dists.min()\n",
    "                if d < min_dist:\n",
    "                    min_dist, best_name = d, name\n",
    "            \n",
    "            # 判断是否匹配\n",
    "            if min_dist > self.threshold:\n",
    "                best_name = 'Unknown'\n",
    "            \n",
    "            confidence = max(0, 1 - min_dist / 2)\n",
    "            results.append({\n",
    "                'name': best_name,\n",
    "                'confidence': confidence,\n",
    "                'distance': min_dist,\n",
    "                'box': box.astype(int),\n",
    "                'detection_prob': prob\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize(self, image_path, save_path=None):\n",
    "        \"\"\"\n",
    "        可视化多人脸识别结果\n",
    "        \"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        results = self.recognize_all(image_path)\n",
    "        \n",
    "        if not results:\n",
    "            print('未检测到人脸')\n",
    "            plt.imshow(img_rgb)\n",
    "            plt.title('No faces detected')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            return results\n",
    "        \n",
    "        # 绘制边界框和标签\n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, 10))[:, :3] * 255\n",
    "        \n",
    "        for i, res in enumerate(results):\n",
    "            box = res['box']\n",
    "            name = res['name']\n",
    "            conf = res['confidence']\n",
    "            \n",
    "            color = tuple(map(int, colors[i % len(colors)]))\n",
    "            \n",
    "            # 绘制边界框\n",
    "            cv2.rectangle(img_rgb, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "            \n",
    "            # 绘制标签背景\n",
    "            label = f\"{name} ({conf:.1%})\"\n",
    "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            cv2.rectangle(img_rgb, (box[0], box[1]-25), (box[0]+w+5, box[1]), color, -1)\n",
    "            \n",
    "            # 绘制文字\n",
    "            cv2.putText(img_rgb, label, (box[0]+2, box[1]-8),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # 显示结果\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f'Multi-Face Recognition: {len(results)} faces detected')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            print(f'结果已保存: {save_path}')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # 打印详细结果\n",
    "        print(f'\\n检测到 {len(results)} 张人脸:')\n",
    "        print('-' * 50)\n",
    "        for i, res in enumerate(results, 1):\n",
    "            print(f\"{i}. {res['name']}: 置信度={res['confidence']:.1%}, \"\n",
    "                  f\"距离={res['distance']:.3f}, 检测概率={res['detection_prob']:.1%}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "print('MultiFaceRecognizer 类定义完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建多人脸识别器\n",
    "multi_recognizer = MultiFaceRecognizer(model, face_db, cfg.THRESHOLD)\n",
    "\n",
    "# 测试多人脸检测\n",
    "# 从LFW目录获取测试图片（因为缓存版本samples中是tensor而非路径）\n",
    "test_person = [d for d in os.listdir(cfg.DATA_ROOT) if os.path.isdir(os.path.join(cfg.DATA_ROOT, d))][0]\n",
    "test_folder = os.path.join(cfg.DATA_ROOT, test_person)\n",
    "test_img_path = os.path.join(test_folder, os.listdir(test_folder)[0])\n",
    "print(f'测试图像: {test_img_path}')\n",
    "\n",
    "# 运行多人脸识别\n",
    "results = multi_recognizer.visualize(test_img_path, save_path=cfg.MULTI_FACE_PATH)\n",
    "print(f'结果已保存: {cfg.MULTI_FACE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_face_image(n_faces=4, save_path=None):\n",
    "    \"\"\"\n",
    "    创建包含多个人脸的测试图像（拼接方式）\n",
    "    从LFW原始目录读取图片\n",
    "    \"\"\"\n",
    "    save_path = save_path or f'{cfg.RESULTS_DIR}/multi_face_test.jpg'\n",
    "    \n",
    "    # 从LFW目录获取图片路径\n",
    "    all_persons = [d for d in os.listdir(cfg.DATA_ROOT) if os.path.isdir(os.path.join(cfg.DATA_ROOT, d))]\n",
    "    selected_persons = random.sample(all_persons, min(n_faces, len(all_persons)))\n",
    "    \n",
    "    images = []\n",
    "    for person in selected_persons:\n",
    "        person_folder = os.path.join(cfg.DATA_ROOT, person)\n",
    "        img_files = [f for f in os.listdir(person_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        if img_files:\n",
    "            img_path = os.path.join(person_folder, img_files[0])\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((200, 200))\n",
    "            images.append(np.array(img))\n",
    "    \n",
    "    if not images:\n",
    "        print('错误：没有找到测试图片')\n",
    "        return None\n",
    "    \n",
    "    # 拼接图像（2行）\n",
    "    rows = 2\n",
    "    cols = (len(images) + 1) // 2\n",
    "    h, w = 200, 200\n",
    "    canvas = np.ones((rows * h, cols * w, 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        r, c = i // cols, i % cols\n",
    "        canvas[r*h:(r+1)*h, c*w:(c+1)*w] = img\n",
    "    \n",
    "    # 保存\n",
    "    Image.fromarray(canvas).save(save_path)\n",
    "    print(f'多人脸测试图像已创建: {save_path}')\n",
    "    return save_path\n",
    "\n",
    "# 创建多人脸测试图像\n",
    "multi_test_path = create_multi_face_image(n_faces=4)\n",
    "\n",
    "# 测试多人脸识别\n",
    "if multi_test_path:\n",
    "    print('\\n测试多人脸识别:')\n",
    "    multi_detection_path = f'{cfg.RESULTS_DIR}/multi_face_detection_result.png'\n",
    "    results = multi_recognizer.visualize(multi_test_path, save_path=multi_detection_path)\n",
    "    print(f'检测结果已保存: {multi_detection_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多人脸识别API使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === API 使用示例（以下代码演示如何调用） ===\n",
    "# 注意：以下使用前面创建的测试图片进行演示\n",
    "\n",
    "# 1. 初始化多人脸识别器\n",
    "# multi_recognizer = MultiFaceRecognizer(model, face_db, threshold=0.6)\n",
    "\n",
    "# 2. 识别图像中的所有人脸（使用实际存在的测试图片）\n",
    "demo_image = f'{cfg.RESULTS_DIR}/multi_face_test.jpg'  # 前面创建的测试图\n",
    "if os.path.exists(demo_image):\n",
    "    results = multi_recognizer.recognize_all(demo_image)\n",
    "    \n",
    "    # 3. 遍历结果\n",
    "    print('=== API调用示例 ===')\n",
    "    for res in results:\n",
    "        print(f\"姓名: {res['name']}\")\n",
    "        print(f\"置信度: {res['confidence']:.1%}\")\n",
    "        print(f\"边界框: {res['box']}\")\n",
    "        print('-' * 30)\n",
    "    \n",
    "    # 4. 可视化结果\n",
    "    api_demo_path = f'{cfg.RESULTS_DIR}/api_demo_result.png'\n",
    "    multi_recognizer.visualize(demo_image, save_path=api_demo_path)\n",
    "else:\n",
    "    print('请先运行前面的单元格生成测试图片')\n",
    "    print(f'预期路径: {demo_image}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
